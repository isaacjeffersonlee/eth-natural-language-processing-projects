{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cac50491",
      "metadata": {
        "id": "cac50491"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this practical part of the assignment, you will implement a model that takes a sentence as input and predicts the most likely CFG parse tree given that sentence:\n",
        "$$\n",
        "\\mathbf{t} = \\text{argmax}_\\mathbf{t}P(\\mathbf{t}|\\mathbf{s})\n",
        "$$\n",
        "\n",
        "\n",
        "You will do this by converting the words into embeddings, and then implementing the CKY algorithm on top of an LSTM which you will train end-to-end."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qikEanUG5tFC",
      "metadata": {
        "id": "qikEanUG5tFC"
      },
      "source": [
        "## Dependencies\n",
        "Please run the following cell to install the necessary dependencies for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8683774b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8683774b",
        "outputId": "e6b66bbf-efd8-4c64-915e-110c41c387ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dynet\n",
            "  Downloading dyNET-2.1.2-cp38-cp38-manylinux1_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dynet) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from dynet) (0.29.32)\n",
            "Installing collected packages: dynet\n",
            "Successfully installed dynet-2.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install dynet\n",
        "!pip install svgling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OEeO7orj5xdz",
      "metadata": {
        "id": "OEeO7orj5xdz"
      },
      "source": [
        "Also, please download [this folder](https://drive.google.com/drive/folders/1FgT2bQdH0eCDDaqkDGk7hORUUDGd6a9t?usp=sharing) and upload it to your google drive, and then run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ZX7mMf0Z5z85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX7mMf0Z5z85",
        "outputId": "0538319c-9ff9-46b4-ffef-22e2ebae72d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/NLP/Assignment_4/nlp-h2022-parsing\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/Colab Notebooks/NLP/Assignment_4/nlp-h2022-parsing'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842646d2",
      "metadata": {
        "id": "842646d2"
      },
      "source": [
        "# 1. Training Data\n",
        "\n",
        "In this section, you will download, interact with, and clean the data which you will use to train and test your model. We will be using the Penn Treebank, an corpus of sentences annotated with Part of Speech tags and CFG parse trees. For ease of computation under limited resources, we will be using a fraction (10%) of the treebank corpus which is distributed with the **nltk** python library."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a4c4e6",
      "metadata": {
        "id": "41a4c4e6"
      },
      "source": [
        "## The Raw Data\n",
        "Download the data by executing the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "13da9ebc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13da9ebc",
        "outputId": "c95d5ba0-11a4-4d17-b39d-ccf9e2244bac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
        "nltk.download('treebank')\n",
        "treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bf62ed",
      "metadata": {
        "id": "a0bf62ed"
      },
      "source": [
        "Have a look at the first few examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "106118f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "106118f0",
        "outputId": "9a40c914-b186-4a1c-c291-0f6de8bf9994"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Tree('S', [Tree('NP-SBJ', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])]),\n",
              " Tree('S', [Tree('NP-SBJ-1', [Tree('NP', [Tree('NNP', ['Rudolph']), Tree('NNP', ['Agnew'])]), Tree(',', [',']), Tree('UCP', [Tree('ADJP', [Tree('NP', [Tree('CD', ['55']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree('CC', ['and']), Tree('NP', [Tree('NP', [Tree('JJ', ['former']), Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NNP', ['Consolidated']), Tree('NNP', ['Gold']), Tree('NNP', ['Fields']), Tree('NNP', ['PLC'])])])])]), Tree(',', [','])]), Tree('VP', [Tree('VBD', ['was']), Tree('VP', [Tree('VBN', ['named']), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*-1'])]), Tree('NP-PRD', [Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['this']), Tree('JJ', ['British']), Tree('JJ', ['industrial']), Tree('NN', ['conglomerate'])])])])])])]), Tree('.', ['.'])])]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treebank.parsed_sents()[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5177c2f",
      "metadata": {
        "id": "c5177c2f"
      },
      "source": [
        "The parenthes encode a tree structure which can be pretty printed by calling a single example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "09742f39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "09742f39",
        "outputId": "2df6ff57-48f3-4a94-d9ea-e54d6a2c8f9d"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"312px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,856.0,312.0\" width=\"856px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"35.514%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"42.1053%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Pierre</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.89474%\" x=\"42.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.1053%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"68.75%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">61</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.6364%\" x=\"36.3636%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">years</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.1818%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.375%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"31.25%\" x=\"68.75%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">old</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.375%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.89474%\" x=\"92.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.0526%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.757%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.6822%\" x=\"35.514%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"9.09091%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">MD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">will</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.54545%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90.9091%\" x=\"9.09091%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"10%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">join</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"20%\" x=\"10%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">board</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"53.3333%\" x=\"30%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP-CLR</text></svg><svg width=\"12.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">as</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"87.5%\" x=\"12.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"14.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">nonexecutive</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"39.2857%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35.7143%\" x=\"64.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">director</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1429%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"16.6667%\" x=\"83.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-TMP</text></svg><svg width=\"60%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Nov.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40%\" x=\"60%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">29</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.6667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.5455%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.3551%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.80374%\" x=\"97.1963%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.5981%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
            "text/plain": [
              "Tree('S', [Tree('NP-SBJ', [Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]), Tree(',', [',']), Tree('ADJP', [Tree('NP', [Tree('CD', ['61']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree(',', [','])]), Tree('VP', [Tree('MD', ['will']), Tree('VP', [Tree('VB', ['join']), Tree('NP', [Tree('DT', ['the']), Tree('NN', ['board'])]), Tree('PP-CLR', [Tree('IN', ['as']), Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])])]), Tree('NP-TMP', [Tree('NNP', ['Nov.']), Tree('CD', ['29'])])])]), Tree('.', ['.'])])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treebank.parsed_sents()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27023347",
      "metadata": {
        "id": "27023347"
      },
      "source": [
        "## Cleaning the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46f4c176",
      "metadata": {
        "id": "46f4c176"
      },
      "source": [
        "Next, we will prepare the data so it can be used to train our parser. For this part, please make yourself familiar with the [nltk.tree](https://www.nltk.org/_modules/nltk/tree.html) module.\n",
        "\n",
        "Look at the following subtree. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "361ba371",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "361ba371",
        "outputId": "4947b176-b056-4688-e07f-1d6cfcf4cb38"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,880.0,360.0\" width=\"880px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"15.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"64.7059%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Lorillard</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.3529%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35.2941%\" x=\"64.7059%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Inc.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.3529%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.72727%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.72727%\" x=\"15.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.8182%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"79.0909%\" x=\"18.1818%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"12.6437%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">unit</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.32184%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40.2299%\" x=\"12.6437%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"11.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.71429%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"88.5714%\" x=\"11.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"54.8387%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York-based</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"54.8387%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Loews</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.129%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Corp.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.7586%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"47.1264%\" x=\"52.8736%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">SBAR</text></svg><svg width=\"19.5122%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WHNP-2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">WDT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">that</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.7561%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.4878%\" x=\"19.5122%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"24.2424%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-NONE-</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">*T*-2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.1212%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"75.7576%\" x=\"24.2424%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"28%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">makes</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72%\" x=\"28%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"33.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Kent</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.6667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"66.6667%\" x=\"33.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cigarettes</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66.6667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"62.1212%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.7561%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"76.4368%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"2.72727%\" x=\"97.2727%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.6364%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
            "text/plain": [
              "Tree('NP-SBJ', [Tree('NP', [Tree('NNP', ['Lorillard']), Tree('NNP', ['Inc.'])]), Tree(',', [',']), Tree('NP', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['unit'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('ADJP', [Tree('JJ', ['New']), Tree('JJ', ['York-based'])]), Tree('NNP', ['Loews']), Tree('NNP', ['Corp.'])])]), Tree('SBAR', [Tree('WHNP-2', [Tree('WDT', ['that'])]), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*T*-2'])]), Tree('VP', [Tree('VBZ', ['makes']), Tree('NP', [Tree('NNP', ['Kent']), Tree('NNS', ['cigarettes'])])])])])]), Tree(',', [','])])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "treebank.parsed_sents()[5][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7e23fb",
      "metadata": {
        "id": "4e7e23fb"
      },
      "source": [
        "First, note that nonterminals can have a variable number of children. However, in order for CKY to work, we require the data to be in Chomsky Normal Form (CNF), i.e. it needs to be binarized. \n",
        "We also want to simplify tags that have hyphens in them, and filter out -NONE- tags (which are used e.g. to indicate relative clauses).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc669f5",
      "metadata": {
        "id": "9bc669f5"
      },
      "source": [
        "### 1.1 Removing -NONE-, -RCB-, and -LRB- tags\n",
        "We want to remove `-NONE-`, `-LRB-` and `-RCB-` tags. For the sake of simplicity, we will remove any tree that contains these tags. Write a method that returns True if a tree passed to it contains such tags. In a comment (without implementing the code), give two other ways `-NONE-` tags could be handled more data efficiently without affecting the grammaticality of the sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "12d55a1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12d55a1f",
        "outputId": "3964febb-711e-4d07-e9b2-84bf9f2a2167"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import Tree\n",
        "\n",
        "bad_tags = ['-NONE-', '-LRB-', '-RCB-']\n",
        "\n",
        "contains_none_tags = lambda tree: bool(sum([1 if bad_tag in tree._pformat_flat(\"\", \"()\", False) else 0 for bad_tag in bad_tags]))\n",
        "    \n",
        "contains_none_tags(treebank.parsed_sents()[5][0]) # this should return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa0ee52e",
      "metadata": {
        "id": "aa0ee52e"
      },
      "source": [
        "### 1.2 Simplifying Functional Tags\n",
        "Write a method that takes in tags and only keeps the part before the first hyphen if it is hyphenated - e.g. `NP-SBJ` should become `NP`. Then write a method that traverses a tree and updates its tags in place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "003d7dd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "003d7dd4",
        "outputId": "c3b6cb3b-bfa6-45c5-c545-a5a38b65f91c"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,680.0,360.0\" width=\"680px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"38.4615%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Mr.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.2308%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.5385%\" x=\"38.4615%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.2308%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.64706%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"81.1765%\" x=\"15.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.24638%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">is</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.62319%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.7536%\" x=\"7.24638%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"15.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.8125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.375%\" x=\"15.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"7.40741%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.7037%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.5926%\" x=\"7.40741%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Elsevier</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">N.V.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6%\" x=\"32%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"62%\" x=\"38%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.129%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.06452%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"16.129%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Dutch</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"38.7097%\" x=\"38.7097%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">publishing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.0645%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">group</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.7037%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.6232%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.8824%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.52941%\" x=\"96.4706%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.2353%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def simplify_functional_tag(tag):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        tag: string\n",
        "    \n",
        "    returns:\n",
        "        the tag up to the first hyphen\n",
        "    \n",
        "    \"\"\"\n",
        "    bad_tags = ['-NONE-', '-LRB-', '-RCB-']\n",
        "    if tag in bad_tags or '-' not in tag:\n",
        "        return tag\n",
        "    else:\n",
        "        return tag.split('-')[0]\n",
        "\n",
        "def simplify_tags(tree):\n",
        "    \"\"\"\n",
        "    Traverses a parse tree and simplifies tags containing hyphens\n",
        "    \n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "        \n",
        "    returns: \n",
        "        parse tree with simplified tags (up to the first hyphen)\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "    leaves = tree.leaves()\n",
        "    simplified_tree = tree.copy()\n",
        "    def visitor(tree):\n",
        "        if tree in leaves: return tree\n",
        "        tree.set_label(simplify_functional_tag(tree.label()))\n",
        "        for child in tree:\n",
        "            visitor(child)\n",
        "\n",
        "    visitor(tree)\n",
        "    return tree\n",
        "\n",
        "    \n",
        "    ### YOUR CODE END\n",
        "    \n",
        "simplified_tree = treebank.parsed_sents()[1].copy(deep=True)\n",
        "simplify_tags(simplified_tree)\n",
        "simplified_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0b3cdf",
      "metadata": {
        "id": "7d0b3cdf"
      },
      "source": [
        "### 1.3 Binarizing the Parse Trees\n",
        "To remove unary derivations and convert the training trees to binary trees, we will use the functions `collapse_unary` and `chomsky_normal_form` in [nltk.tree](https://www.nltk.org/_modules/nltk/tree.html). Write down the call you will make using horizontal markov smoothing of 1 and vertical markov smoothing of 0, factoring right, and using ^ for parent and | for child. Explain the meaning and the purpose of these parameters in a comment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1ba69bf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "1ba69bf6",
        "outputId": "bb780413-24c3-4376-93dc-654eefa3b00e"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,680.0,360.0\" width=\"680px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"38.4615%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Mr.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.2308%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.5385%\" x=\"38.4615%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.2308%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.64706%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"81.1765%\" x=\"15.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.24638%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">is</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.62319%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.7536%\" x=\"7.24638%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-PRD</text></svg><svg width=\"15.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.8125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.375%\" x=\"15.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"7.40741%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.7037%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.5926%\" x=\"7.40741%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Elsevier</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">N.V.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"6%\" x=\"32%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"35%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"62%\" x=\"38%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.129%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.06452%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"16.129%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Dutch</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.4194%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"38.7097%\" x=\"38.7097%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">publishing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.0645%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.5806%\" x=\"77.4194%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">group</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.7097%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.7037%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.6232%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.8824%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.52941%\" x=\"96.4706%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.2353%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
            "text/plain": [
              "Tree('S', [Tree('NP-SBJ', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NNP', ['Dutch']), Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])]), Tree('.', ['.'])])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"552px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,680.0,552.0\" width=\"680px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"15.2941%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-SBJ</text></svg><svg width=\"38.4615%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Mr.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"19.2308%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.5385%\" x=\"38.4615%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.2308%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.64706%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.7059%\" x=\"15.2941%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S|&lt;VP&gt;</text></svg><svg width=\"95.8333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"7.24638%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBZ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">is</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.62319%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.7536%\" x=\"7.24638%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP-PRD</text></svg><svg width=\"15.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chairman</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.8125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"84.375%\" x=\"15.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"7.40741%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.7037%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"92.5926%\" x=\"7.40741%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"32%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Elsevier</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">N.V.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"16%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"68%\" x=\"32%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;,&gt;</text></svg><svg width=\"8.82353%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.41176%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"91.1765%\" x=\"8.82353%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"16.129%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.06452%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"83.871%\" x=\"16.129%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;NNP&gt;</text></svg><svg width=\"26.9231%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Dutch</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.4615%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"73.0769%\" x=\"26.9231%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;VBG&gt;</text></svg><svg width=\"63.1579%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBG</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">publishing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.5789%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"36.8421%\" x=\"63.1579%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">group</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.5789%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.4615%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.0645%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.4118%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"66%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.7037%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"53.6232%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.9167%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.16667%\" x=\"95.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.9167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.6471%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
            "text/plain": [
              "Tree('S', [Tree('NP-SBJ', [Tree('NNP', ['Mr.']), Tree('NNP', ['Vinken'])]), Tree('S|<VP>', [Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('NP', [Tree('NN', ['chairman'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('NP', [Tree('NNP', ['Elsevier']), Tree('NNP', ['N.V.'])]), Tree('NP|<,>', [Tree(',', [',']), Tree('NP', [Tree('DT', ['the']), Tree('NP|<NNP>', [Tree('NNP', ['Dutch']), Tree('NP|<VBG>', [Tree('VBG', ['publishing']), Tree('NN', ['group'])])])])])])])])]), Tree('.', ['.'])])])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tree import collapse_unary, chomsky_normal_form\n",
        "\n",
        "def binarize(tree):\n",
        "    \"\"\"\n",
        "    Collapses unary productions and binarizes a parse tree in place.\n",
        "    \n",
        "    parameters:\n",
        "        tree: parse tree\n",
        "        \n",
        "    returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    ### YOUR CODE AND COMMENTS HERE\n",
        "    tree.collapse_unary(collapsePOS=False)\n",
        "    tree.chomsky_normal_form(\n",
        "        factor=\"right\", # The side that gets factored, i.e if we have N -> N1 N2 N3 then 'left' => N -> N1|N2 N3\n",
        "        horzMarkov=1,   # Markov order for sibling smoothing in artificial nodes (number of sibling nodes to include in artificial combined nodes)\n",
        "        vertMarkov=0,   # Markov order for parent smoothing\n",
        "        childChar=\"|\",  # String separating the original non-terminals that get combined to create the artificial terminals\n",
        "        parentChar=\"^\"  # String used to separate the node representation from its vertical annotation\n",
        "    )\n",
        "    ### YOUR CODE END\n",
        "\n",
        "\n",
        "test_tree = treebank.parsed_sents()[1].copy(deep=True)\n",
        "display(test_tree)\n",
        "binarize(test_tree)\n",
        "test_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d60ddd21",
      "metadata": {
        "id": "d60ddd21"
      },
      "source": [
        "### 1.4 Run Data Preprocessing\n",
        "\n",
        "Bringing all of these together, write a method that takes a set of trees and returns a list of (copied) cleaned trees:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9d8b80f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "9d8b80f4",
        "outputId": "b7d4fb36-d4a5-4ae2-950b-a8e13c454058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "986 trees cleaned!\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"504px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,856.0,504.0\" width=\"856px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"35.514%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"42.1053%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Pierre</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Vinken</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.0526%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"57.8947%\" x=\"42.1053%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;,&gt;</text></svg><svg width=\"13.6364%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.81818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"86.3636%\" x=\"13.6364%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;ADJP&gt;</text></svg><svg width=\"84.2105%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJP</text></svg><svg width=\"68.75%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"36.3636%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">61</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.1818%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"63.6364%\" x=\"36.3636%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNS</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">years</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"68.1818%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.375%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"31.25%\" x=\"68.75%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">old</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"84.375%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.1053%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"15.7895%\" x=\"84.2105%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.1053%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.8182%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.0526%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.757%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"64.486%\" x=\"35.514%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S|&lt;VP&gt;</text></svg><svg width=\"95.6522%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"9.09091%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">MD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">will</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.54545%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90.9091%\" x=\"9.09091%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"10%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">join</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"90%\" x=\"10%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP|&lt;NP&gt;</text></svg><svg width=\"22.2222%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">board</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.1111%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.7778%\" x=\"22.2222%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP|&lt;PP&gt;</text></svg><svg width=\"76.1905%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"12.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">as</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"87.5%\" x=\"12.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"14.2857%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.14286%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"85.7143%\" x=\"14.2857%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP|&lt;JJ&gt;</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">nonexecutive</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">director</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.1429%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.0952%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"23.8095%\" x=\"76.1905%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"60%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Nov.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40%\" x=\"60%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CD</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">29</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.0952%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.1111%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.5455%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.8261%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"4.34783%\" x=\"95.6522%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.8261%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.757%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
            "text/plain": [
              "Tree('S', [Tree('NP', [Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]), Tree('NP|<,>', [Tree(',', [',']), Tree('NP|<ADJP>', [Tree('ADJP', [Tree('NP', [Tree('CD', ['61']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree(',', [','])])])]), Tree('S|<VP>', [Tree('VP', [Tree('MD', ['will']), Tree('VP', [Tree('VB', ['join']), Tree('VP|<NP>', [Tree('NP', [Tree('DT', ['the']), Tree('NN', ['board'])]), Tree('VP|<PP>', [Tree('PP', [Tree('IN', ['as']), Tree('NP', [Tree('DT', ['a']), Tree('NP|<JJ>', [Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])])])]), Tree('NP', [Tree('NNP', ['Nov.']), Tree('CD', ['29'])])])])])]), Tree('.', ['.'])])])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_trees(trees):\n",
        "    \"\"\"\n",
        "    Cleans parse trees from the penn treebank by performing tag simplification, \n",
        "        binarization, and filtering out trees with NONE tags.\n",
        "    \n",
        "    parameters:\n",
        "        trees: parse trees\n",
        "        \n",
        "    returns:\n",
        "        list of cleaned trees\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "    cleaned_trees = []\n",
        "    for tree in trees:\n",
        "        if not contains_none_tags(tree):\n",
        "            cleaned_tree = tree.copy(deep=True)\n",
        "            simplify_tags(cleaned_tree)\n",
        "            binarize(cleaned_tree)\n",
        "            cleaned_trees.append(cleaned_tree)\n",
        "\n",
        "    return cleaned_trees\n",
        "    ### YOUR CODE END\n",
        "\n",
        "trees_cleaned = clean_trees(treebank.parsed_sents())\n",
        "print(f\"{len(trees_cleaned)} trees cleaned!\")\n",
        "trees_cleaned[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3ed7e9",
      "metadata": {
        "id": "5d3ed7e9"
      },
      "source": [
        "Now we can write the cleaned data to the disk to use as training and test data later (using an 90:10 split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "552b40d7",
      "metadata": {
        "id": "552b40d7"
      },
      "outputs": [],
      "source": [
        "def flatten(tree):\n",
        "    return tree._pformat_flat(\"\", \"()\", False)\n",
        "\n",
        "trees_train = trees_cleaned[:886]\n",
        "trees_test = trees_cleaned[886:]\n",
        "\n",
        "with open(\"data/train.clean\", \"w\") as f:\n",
        "    for tree in trees_train:\n",
        "        flat_tree = flatten(tree)\n",
        "        f.write(f\"{flat_tree}\\n\")\n",
        "        \n",
        "with open(\"data/test.clean\", \"w\") as f:\n",
        "    for tree in trees_test:\n",
        "        flat_tree = flatten(tree)\n",
        "        f.write(f\"{flat_tree}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb16456e",
      "metadata": {
        "id": "cb16456e"
      },
      "source": [
        "# 2. Neural Constituency Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c51466e",
      "metadata": {
        "id": "6c51466e"
      },
      "source": [
        "Now we want to train our model to parse from scratch, by providing it with training examples and optimizing it.\n",
        "We will use a bidirectional LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a4ed8e",
      "metadata": {
        "id": "47a4ed8e"
      },
      "source": [
        "## Defining the vocabulary\n",
        "First, load the training and test data we created in part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3e5ea1fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e5ea1fa",
        "outputId": "067b48c2-1ba0-4243-9d8c-6746a8c55f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 886 training examples.\n",
            "Loaded 100 test examples.\n",
            "Processing trees for training...\n"
          ]
        }
      ],
      "source": [
        "from src import trees\n",
        "\n",
        "train_path = \"data/train.clean\"\n",
        "test_path = \"data/test.clean\"\n",
        "\n",
        "test_treebank = trees.load_trees(test_path)\n",
        "train_treebank = trees.load_trees(train_path)\n",
        "\n",
        "print(f\"Loaded {len(train_treebank)} training examples.\")\n",
        "print(f\"Loaded {len(test_treebank)} test examples.\")\n",
        "\n",
        "print(\"Processing trees for training...\")\n",
        "train_parse = [tree.convert() for tree in train_treebank]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79309372",
      "metadata": {
        "id": "79309372"
      },
      "source": [
        "Then, we collect the vocabulary for words, tags, and labels from the training data, creating a reverse index to look up the index of words in our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "649df1a4",
      "metadata": {
        "id": "649df1a4"
      },
      "outputs": [],
      "source": [
        "from src import vocabulary\n",
        "\n",
        "START = \"<START>\"\n",
        "STOP = \"<STOP>\"\n",
        "UNK = \"<UNK>\"\n",
        "\n",
        "tag_vocab = vocabulary.Vocabulary()\n",
        "tag_vocab.index(START)\n",
        "tag_vocab.index(STOP)\n",
        "\n",
        "word_vocab = vocabulary.Vocabulary()\n",
        "word_vocab.index(START)\n",
        "word_vocab.index(STOP)\n",
        "word_vocab.index(UNK)\n",
        "\n",
        "label_vocab = vocabulary.Vocabulary()\n",
        "label_vocab.index(())\n",
        "\n",
        "for tree in train_parse:\n",
        "    nodes = [tree]\n",
        "    while nodes:\n",
        "        node = nodes.pop()\n",
        "        if isinstance(node, trees.InternalParseNode):\n",
        "            label_vocab.index(node.label)\n",
        "            nodes.extend(reversed(node.children))\n",
        "        else:\n",
        "            tag_vocab.index(node.tag)\n",
        "            word_vocab.index(node.word)\n",
        "\n",
        "tag_vocab.freeze()\n",
        "word_vocab.freeze()\n",
        "label_vocab.freeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0fefeb6",
      "metadata": {
        "id": "f0fefeb6"
      },
      "source": [
        "## Defining the model\n",
        "Now, we will define the neural network model that will predict label scores for spans. The reference implementation uses a bidirectional LSTM which you can define using dynet's [BiRNNBuilder class](https://dynet.readthedocs.io/en/latest/python_ref.html#dynet.BiRNNBuilder). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6e4100b9",
      "metadata": {
        "id": "6e4100b9"
      },
      "outputs": [],
      "source": [
        "import dynet as dy\n",
        "from src.util import Feedforward\n",
        "\n",
        "dy.reset_random_seed(42)\n",
        "\n",
        "# Create a dynet model\n",
        "model = dy.ParameterCollection()\n",
        "parser_model = model.add_subcollection(\"Parser\")\n",
        "\n",
        "batch_size = 10\n",
        "tag_embedding_dim = 50\n",
        "word_embedding_dim = 100\n",
        "lstm_layers = 2\n",
        "lstm_dim = 250\n",
        "label_hidden_dim = 250\n",
        "dropout = 0.4\n",
        "\n",
        "tag_embeddings = parser_model.add_lookup_parameters((tag_vocab.size, tag_embedding_dim))\n",
        "word_embeddings = parser_model.add_lookup_parameters((word_vocab.size, word_embedding_dim))\n",
        "\n",
        "# Create a lstm using the dynet BiRNNBuilder\n",
        "lstm = dy.BiRNNBuilder(\n",
        "    lstm_layers,\n",
        "    tag_embedding_dim + word_embedding_dim,\n",
        "    2 * lstm_dim,\n",
        "    parser_model,\n",
        "    dy.VanillaLSTMBuilder)\n",
        "\n",
        "# Define a Feedforward neural net that predicts the label probabilities given lstm outputs from a sentence\n",
        "f_label = Feedforward(parser_model, 2 * lstm_dim, [label_hidden_dim], label_vocab.size - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9fdaa53",
      "metadata": {
        "id": "e9fdaa53"
      },
      "source": [
        "## 2.1 Generating Embeddings\n",
        "\n",
        "Next we need to convert the words and tags into embeddings that can be fed to the LSTM. Implement the following method.\n",
        "Unknown words should get the embedding of the UNK word.\n",
        "\n",
        "Hint: use the reverse index methods `tag_vocab.index()` and `word_vocab.index()` methods from `vocabulary.py` to find the keys of words and tags in the respective embedding dicts created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2a3895e3",
      "metadata": {
        "id": "2a3895e3"
      },
      "outputs": [],
      "source": [
        "def convert_to_embeddings(sentence):\n",
        "    \"\"\"\n",
        "    Converts a sentence consisting of tags and words into embeddings. \n",
        "        Replaces words not in the vocabulary with with the UNK placeholder.\n",
        "    \n",
        "    params:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "    \n",
        "    return:\n",
        "        dy expression containing a concatenation of all tag embedding/word embedding pairs\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    for tag, word in [(START, START)] + sentence + [(STOP, STOP)]:\n",
        "        tag_embedding = tag_embeddings[tag_vocab.index(tag)]\n",
        "        word = UNK if word not in word_vocab.values else word\n",
        "        word_embedding = word_embeddings[word_vocab.index(word)]\n",
        "        ### YOUR CODE END\n",
        "        embeddings.append(dy.concatenate([tag_embedding, word_embedding]))   \n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FedYhfo9q8Df",
      "metadata": {
        "id": "FedYhfo9q8Df"
      },
      "source": [
        "To test your code, run the following cell on the sentence `The boy ate a pie` with tags ['DT', 'NN', 'VBZ' 'DT', 'NN']:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "09cTYZ1Tq8de",
      "metadata": {
        "id": "09cTYZ1Tq8de"
      },
      "outputs": [],
      "source": [
        "sentence = [('DT', 'The'),('NN','boy'),('VBZ','ate'), ('DT', 'a'), ('NN', 'pie')]\n",
        "embeddings = convert_to_embeddings(sentence)\n",
        "assert len(embeddings)==7\n",
        "assert len(embeddings[0].value())==150\n",
        "assert embeddings[5].value() == dy.concatenate(\n",
        "    [tag_embeddings[tag_vocab.index('NN')],\n",
        "     word_embeddings[word_vocab.index(UNK)]]).value()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5eb2e53",
      "metadata": {
        "id": "b5eb2e53"
      },
      "source": [
        "We can now use the above method to get the lstm outputs for the whole sentence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3d09015f",
      "metadata": {
        "id": "3d09015f"
      },
      "outputs": [],
      "source": [
        "def get_lstm_outputs(sentence, is_train):\n",
        "    \"\"\"\n",
        "    Gets the outputs of the lstm for a given sentence.\n",
        "    \n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        \n",
        "    returns:\n",
        "        lstm_outputs\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    if is_train:\n",
        "        lstm.set_dropout(dropout)\n",
        "    else:\n",
        "        lstm.disable_dropout()\n",
        "    \n",
        "    # Get the tag and word embeddings for the sentence\n",
        "    embeddings = convert_to_embeddings(sentence)\n",
        "    \n",
        "    # Get the output of the LSTM given the embedded sentence\n",
        "    lstm_outputs = lstm.transduce(embeddings)\n",
        "        \n",
        "    return lstm_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcfc975",
      "metadata": {
        "id": "6bcfc975"
      },
      "source": [
        "The following two methods are helper methods which compute the scores for each label given a span."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bf8314af",
      "metadata": {
        "id": "bf8314af"
      },
      "outputs": [],
      "source": [
        "from src.util import augment\n",
        "\n",
        "def get_span_encoding(left, right, lstm_outputs):\n",
        "    \"\"\"\n",
        "    Computes the encoding of a sentence span (substring between two indices) \n",
        "        given the forward and backward outputs in the LSTM.\n",
        "    \n",
        "    parameters:\n",
        "        left: left span index\n",
        "        right: right span index\n",
        "    \n",
        "    returns:\n",
        "        encoding of the span\n",
        "    \"\"\"\n",
        "    forward = (\n",
        "        lstm_outputs[right][:lstm_dim] -\n",
        "        lstm_outputs[left][:lstm_dim])\n",
        "    backward = (\n",
        "        lstm_outputs[left + 1][lstm_dim:] -\n",
        "        lstm_outputs[right + 1][lstm_dim:])\n",
        "    return dy.concatenate([forward, backward])\n",
        "\n",
        "def get_label_scores(left, right, lstm_outputs, gold, force_gold):\n",
        "    \"\"\"\n",
        "    Computes the best label for a given span and its score.\n",
        "    \n",
        "    parameters:\n",
        "        left: left index of the span\n",
        "        right: right index of the span\n",
        "        lstm_outputs: outputs of the lstm when given the sentence\n",
        "        gold reference parse tree for the sentence\n",
        "        force_gold: True if method should construct the gold parse tree \n",
        "          and compute its score\n",
        "        \n",
        "    returns:\n",
        "        (label, score):\n",
        "            label: the highest scoring label if force_gold is False, \n",
        "              or the gold label if force_gold is true\n",
        "            score: the score of the label\n",
        "    \"\"\"\n",
        "    is_train = gold is not None\n",
        "\n",
        "    label_scores = f_label(get_span_encoding(left, right, lstm_outputs))\n",
        "    label_scores = dy.concatenate([dy.zeros(1), label_scores])\n",
        "    \n",
        "    if is_train:\n",
        "        oracle_label = gold.oracle_label(left, right)\n",
        "        oracle_label_index = label_vocab.index(oracle_label)\n",
        "    \n",
        "    if force_gold:\n",
        "        label_score = label_scores[oracle_label_index]\n",
        "        label = oracle_label\n",
        "        \n",
        "    else:\n",
        "        if is_train:\n",
        "            label_scores = augment(label_scores, oracle_label_index)\n",
        "        label_scores_np = label_scores.npvalue()\n",
        "        span = right - left\n",
        "        argmax_label_index = int(\n",
        "                        label_scores_np.argmax() if span < len(sentence) else\n",
        "                        label_scores_np[1:].argmax() + 1)\n",
        "        label = label_vocab.value(argmax_label_index)\n",
        "        label_score = label_scores[argmax_label_index]\n",
        "    return label, label_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fadb8972",
      "metadata": {
        "id": "fadb8972"
      },
      "source": [
        "## 2.2 CKY with estimated label probabilites\n",
        "Now we can implement the parser method. It works like CKY, with some additions.\n",
        "\n",
        "During training, the `gold` parameter is set, representing the reference parse tree. During inference, this is not set and the method simply returns the best scoring parse tree.\n",
        "\n",
        "Your task is to implement the CKY algorithm, iterating through spans and for each pair of span indices dynamically calculate scores and parse trees:\n",
        "1. Use the method `get_label_scores(left, right, lstm_outputs, gold, force_gold)` to get the scores for each label corresponding to the given span (left, right).\n",
        "2. Find the best place to split a given span into two subspans given their respective label scores. (If `force_gold` is set, use the method `tree.oracle_splits(left, right)` from `trees.py` to get the split positions, and use the first of them as the index to split the tree.)\n",
        "3. Calculate the score of the label when splitting at the best index found above and put it into the scores `chart`.\n",
        "4. Get the subtrees for the span and split position, and put the resulting new subtree into the `parse_trees` dict.\n",
        "\n",
        "*Hint: the label scores are stored as dynet expressions, use `.value()` to get the score value.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4fb42e8f",
      "metadata": {
        "id": "4fb42e8f"
      },
      "outputs": [],
      "source": [
        "from src import trees\n",
        "\n",
        "def parse(sentence, gold=None, force_gold=False):\n",
        "    \"\"\"\n",
        "    Generates the best scoring parse tree for a given sentence.\n",
        " \n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        gold: gold reference parse tree for the sentence\n",
        "        force_gold: If true, method will construct the gold parse tree \n",
        "            and compute its score, otherwise it will compute the \n",
        "            best scoring parse tree.\n",
        "        \n",
        "    returns:\n",
        "        (tree, score): \n",
        "            tree: constructed best or gold parse tree\n",
        "            score: score of the constructed parse tree\n",
        "    \"\"\"\n",
        "    N = len(sentence)\n",
        "    \n",
        "    chart = {}\n",
        "    parse_trees = {}\n",
        "    \n",
        "    is_train = gold is not None\n",
        "    lstm_outputs = get_lstm_outputs(sentence, is_train)\n",
        "    \n",
        "    for i in range(N):  # Handle leaf node case\n",
        "        tag, word = sentence[i]\n",
        "        label, score = get_label_scores(i, i + 1, lstm_outputs, gold, force_gold)\n",
        "        tree = trees.LeafParseNode(i, tag, word)\n",
        "        if label:\n",
        "            tree = trees.InternalParseNode(label, [tree])\n",
        "        parse_trees[i, i + 1] = [tree]\n",
        "        chart[i, i + 1] = score\n",
        "    \n",
        "    ### YOUR CODE HERE\n",
        "    for span in range(2, N + 1):\n",
        "        for i in range(N - span + 1):  # Start idx of the span\n",
        "            k = i + span               # End idx of the span\n",
        "            label, score = get_label_scores(i, k, lstm_outputs, gold, force_gold)\n",
        "            if force_gold:\n",
        "                split_idx = gold.oracle_splits(i, k)[0]\n",
        "                max_split_score = chart[i, split_idx] + chart[split_idx, k]\n",
        "            else:\n",
        "                split_scores = [chart[i, j] + chart[j, k] for j in range(i + 1, k - 1 + 1)]\n",
        "                max_split_score = max(split_scores, key=lambda score: score.value())\n",
        "                split_idx = split_scores.index(max_split_score) + (i + 1)  # Account for idx offset\n",
        "\n",
        "            chart[i, k] = max_split_score + score\n",
        "\n",
        "            children = parse_trees[i, split_idx] + parse_trees[split_idx, k]\n",
        "            if label:\n",
        "                parse_trees[i, k] = [trees.InternalParseNode(label, children)]\n",
        "            else:\n",
        "                parse_trees[i, k] = children\n",
        "\n",
        "    ### YOUR CODE END\n",
        "            \n",
        "\n",
        "    assert len(parse_trees[0, N]) == 1        \n",
        "    tree = parse_trees[0, N][0]\n",
        "    score = chart[0, N]\n",
        "    return tree, score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oxIxXPz_rro3",
      "metadata": {
        "id": "oxIxXPz_rro3"
      },
      "source": [
        "Test your code on the sentence from before. Don't worry if the parse tree does not make sense right now, since the model has not been trained yet. You should get the following tree and score:\n",
        "\n",
        "`tree:  (S|<ADJP> (S|<ADJP> (S|<ADJP> (DT The)) (S|<ADJP> (S|<ADJP> (NN boy)) (S|<ADJP> (S|<ADJP> (VBZ ate)) (S|<ADJP> (DT a))))) (S|<ADJP> (NN pie)))`\n",
        "\n",
        "`score:  1.4991785287857056`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "-rhzOod0rrxc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhzOod0rrxc",
        "outputId": "46024fa8-51fe-48ed-d9f1-32d9fe7e7d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dy.parameter(...) call is now DEPRECATED.\n",
            "        There is no longer need to explicitly add parameters to the computation graph.\n",
            "        Any used parameter will be added automatically.\n",
            "tree:  (S|<ADJP> (S|<ADJP> (S|<ADJP> (DT The)) (S|<ADJP> (S|<ADJP> (NN boy)) (S|<ADJP> (S|<ADJP> (VBZ ate)) (S|<ADJP> (DT a))))) (S|<ADJP> (NN pie)))\n",
            "score:  1.4991785287857056\n"
          ]
        }
      ],
      "source": [
        "sentence = [('DT', 'The'),('NN','boy'),('VBZ','ate'), ('DT', 'a'), ('NN', 'pie')]\n",
        "tree, score =  parse(sentence)\n",
        "print(\"tree: \", tree.convert().linearize())\n",
        "print(\"score: \", score.value())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e04c2e",
      "metadata": {
        "id": "03e04c2e"
      },
      "source": [
        "## 2.3 Training the model\n",
        "\n",
        "Now we can train our model on the training data. Your first task is to implement a method that calculates the loss for a predicted parse tree given a sentence.\n",
        "\n",
        "Do this by first calculating the score and predicted parse tree, then calulating the score of a given gold parse tree.\n",
        "\n",
        "You should implement hinge loss where the loss is 0 if the predicted tree was correct and otherwise the difference between the score of the predicted tree and that of the reference tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0c088e03",
      "metadata": {
        "id": "0c088e03"
      },
      "outputs": [],
      "source": [
        "def hinge_loss(sentence, gold_tree):\n",
        "    \"\"\"\n",
        "    parameters:\n",
        "        sentence: list of tuples of (tag, word)\n",
        "        gold_tree: gold reference parse tree for the sentence\n",
        "        \n",
        "    returns:\n",
        "        dynet expression containing the loss, i.e. dy.zeros(1) if correct and \n",
        "        difference between parse and oracle score if incorrect.\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "    pred_tree, score = parse(sentence, gold=gold_tree)\n",
        "    _, gold_score = parse(sentence, gold=gold_tree, force_gold=True)\n",
        "    loss = dy.zeros(1) if pred_tree.convert().linearize() == gold_tree.convert().linearize() else score - gold_score\n",
        "    ### YOUR CODE END\n",
        "    \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09847de5",
      "metadata": {
        "id": "09847de5"
      },
      "source": [
        "Now run training for 10 epochs, reporting the batch loss for each batch.\n",
        "\n",
        "You should iterate through the trees, extract the input sentence from the tree and generate the loss for each of them using the loss function defined above. Then add the loss to the `batch_losses` list and increase the `total_processed` counter at every sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "dca5b938",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dca5b938",
        "outputId": "7e0cd5ea-f3b4-442d-fa6e-1ee59aec17b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 batch 1/89 processed 10 batch-loss 34.8215 epoch-elapsed 0h00m03s total-elapsed 0h00m03s\n",
            "epoch 0 batch 2/89 processed 20 batch-loss 37.5980 epoch-elapsed 0h00m06s total-elapsed 0h00m06s\n",
            "epoch 0 batch 3/89 processed 30 batch-loss 31.1126 epoch-elapsed 0h00m08s total-elapsed 0h00m08s\n",
            "epoch 0 batch 4/89 processed 40 batch-loss 38.9504 epoch-elapsed 0h00m11s total-elapsed 0h00m11s\n",
            "epoch 0 batch 5/89 processed 50 batch-loss 34.9492 epoch-elapsed 0h00m13s total-elapsed 0h00m13s\n",
            "epoch 0 batch 6/89 processed 60 batch-loss 45.1657 epoch-elapsed 0h00m17s total-elapsed 0h00m17s\n",
            "epoch 0 batch 7/89 processed 70 batch-loss 32.1836 epoch-elapsed 0h00m19s total-elapsed 0h00m19s\n",
            "epoch 0 batch 8/89 processed 80 batch-loss 32.6330 epoch-elapsed 0h00m21s total-elapsed 0h00m21s\n",
            "epoch 0 batch 9/89 processed 90 batch-loss 33.2372 epoch-elapsed 0h00m24s total-elapsed 0h00m24s\n",
            "epoch 0 batch 10/89 processed 100 batch-loss 35.8003 epoch-elapsed 0h00m26s total-elapsed 0h00m26s\n",
            "epoch 0 batch 11/89 processed 110 batch-loss 32.8355 epoch-elapsed 0h00m28s total-elapsed 0h00m28s\n",
            "epoch 0 batch 12/89 processed 120 batch-loss 34.5752 epoch-elapsed 0h00m31s total-elapsed 0h00m31s\n",
            "epoch 0 batch 13/89 processed 130 batch-loss 38.0875 epoch-elapsed 0h00m34s total-elapsed 0h00m34s\n",
            "epoch 0 batch 14/89 processed 140 batch-loss 26.5989 epoch-elapsed 0h00m36s total-elapsed 0h00m36s\n",
            "epoch 0 batch 15/89 processed 150 batch-loss 35.1166 epoch-elapsed 0h00m38s total-elapsed 0h00m38s\n",
            "epoch 0 batch 16/89 processed 160 batch-loss 33.3548 epoch-elapsed 0h00m41s total-elapsed 0h00m41s\n",
            "epoch 0 batch 17/89 processed 170 batch-loss 33.0130 epoch-elapsed 0h00m43s total-elapsed 0h00m43s\n",
            "epoch 0 batch 18/89 processed 180 batch-loss 29.9977 epoch-elapsed 0h00m45s total-elapsed 0h00m45s\n",
            "epoch 0 batch 19/89 processed 190 batch-loss 22.3513 epoch-elapsed 0h00m47s total-elapsed 0h00m47s\n",
            "epoch 0 batch 20/89 processed 200 batch-loss 32.1887 epoch-elapsed 0h00m49s total-elapsed 0h00m49s\n",
            "epoch 0 batch 21/89 processed 210 batch-loss 41.4287 epoch-elapsed 0h00m53s total-elapsed 0h00m53s\n",
            "epoch 0 batch 22/89 processed 220 batch-loss 42.5338 epoch-elapsed 0h00m56s total-elapsed 0h00m56s\n",
            "epoch 0 batch 23/89 processed 230 batch-loss 25.5503 epoch-elapsed 0h00m58s total-elapsed 0h00m58s\n",
            "epoch 0 batch 24/89 processed 240 batch-loss 26.0172 epoch-elapsed 0h01m00s total-elapsed 0h01m00s\n",
            "epoch 0 batch 25/89 processed 250 batch-loss 33.6566 epoch-elapsed 0h01m03s total-elapsed 0h01m03s\n",
            "epoch 0 batch 26/89 processed 260 batch-loss 39.8567 epoch-elapsed 0h01m06s total-elapsed 0h01m06s\n",
            "epoch 0 batch 27/89 processed 270 batch-loss 28.9698 epoch-elapsed 0h01m08s total-elapsed 0h01m08s\n",
            "epoch 0 batch 28/89 processed 280 batch-loss 34.2241 epoch-elapsed 0h01m11s total-elapsed 0h01m11s\n",
            "epoch 0 batch 29/89 processed 290 batch-loss 38.9167 epoch-elapsed 0h01m14s total-elapsed 0h01m14s\n",
            "epoch 0 batch 30/89 processed 300 batch-loss 25.8643 epoch-elapsed 0h01m16s total-elapsed 0h01m16s\n",
            "epoch 0 batch 31/89 processed 310 batch-loss 33.0943 epoch-elapsed 0h01m18s total-elapsed 0h01m18s\n",
            "epoch 0 batch 32/89 processed 320 batch-loss 28.9248 epoch-elapsed 0h01m20s total-elapsed 0h01m20s\n",
            "epoch 0 batch 33/89 processed 330 batch-loss 40.3157 epoch-elapsed 0h01m24s total-elapsed 0h01m24s\n",
            "epoch 0 batch 34/89 processed 340 batch-loss 25.0646 epoch-elapsed 0h01m26s total-elapsed 0h01m26s\n",
            "epoch 0 batch 35/89 processed 350 batch-loss 27.9427 epoch-elapsed 0h01m28s total-elapsed 0h01m28s\n",
            "epoch 0 batch 36/89 processed 360 batch-loss 33.4077 epoch-elapsed 0h01m31s total-elapsed 0h01m31s\n",
            "epoch 0 batch 37/89 processed 370 batch-loss 38.5298 epoch-elapsed 0h01m34s total-elapsed 0h01m34s\n",
            "epoch 0 batch 38/89 processed 380 batch-loss 29.3493 epoch-elapsed 0h01m36s total-elapsed 0h01m36s\n",
            "epoch 0 batch 39/89 processed 390 batch-loss 32.4187 epoch-elapsed 0h01m39s total-elapsed 0h01m39s\n",
            "epoch 0 batch 40/89 processed 400 batch-loss 33.7068 epoch-elapsed 0h01m41s total-elapsed 0h01m41s\n",
            "epoch 0 batch 41/89 processed 410 batch-loss 37.3412 epoch-elapsed 0h01m44s total-elapsed 0h01m44s\n",
            "epoch 0 batch 42/89 processed 420 batch-loss 27.9180 epoch-elapsed 0h01m46s total-elapsed 0h01m46s\n",
            "epoch 0 batch 43/89 processed 430 batch-loss 23.9116 epoch-elapsed 0h01m48s total-elapsed 0h01m48s\n",
            "epoch 0 batch 44/89 processed 440 batch-loss 27.6950 epoch-elapsed 0h01m50s total-elapsed 0h01m50s\n",
            "epoch 0 batch 45/89 processed 450 batch-loss 32.8563 epoch-elapsed 0h01m53s total-elapsed 0h01m53s\n",
            "epoch 0 batch 46/89 processed 460 batch-loss 35.6030 epoch-elapsed 0h01m56s total-elapsed 0h01m56s\n",
            "epoch 0 batch 47/89 processed 470 batch-loss 41.7374 epoch-elapsed 0h01m59s total-elapsed 0h01m59s\n",
            "epoch 0 batch 48/89 processed 480 batch-loss 46.3201 epoch-elapsed 0h02m03s total-elapsed 0h02m03s\n",
            "epoch 0 batch 49/89 processed 490 batch-loss 43.3684 epoch-elapsed 0h02m07s total-elapsed 0h02m07s\n",
            "epoch 0 batch 50/89 processed 500 batch-loss 29.7872 epoch-elapsed 0h02m10s total-elapsed 0h02m10s\n",
            "epoch 0 batch 51/89 processed 510 batch-loss 36.9221 epoch-elapsed 0h02m13s total-elapsed 0h02m13s\n",
            "epoch 0 batch 52/89 processed 520 batch-loss 32.6148 epoch-elapsed 0h02m15s total-elapsed 0h02m15s\n",
            "epoch 0 batch 53/89 processed 530 batch-loss 45.8319 epoch-elapsed 0h02m19s total-elapsed 0h02m19s\n",
            "epoch 0 batch 54/89 processed 540 batch-loss 28.5715 epoch-elapsed 0h02m21s total-elapsed 0h02m21s\n",
            "epoch 0 batch 55/89 processed 550 batch-loss 28.7979 epoch-elapsed 0h02m24s total-elapsed 0h02m24s\n",
            "epoch 0 batch 56/89 processed 560 batch-loss 27.7385 epoch-elapsed 0h02m26s total-elapsed 0h02m26s\n",
            "epoch 0 batch 57/89 processed 570 batch-loss 21.8841 epoch-elapsed 0h02m27s total-elapsed 0h02m27s\n",
            "epoch 0 batch 58/89 processed 580 batch-loss 29.6489 epoch-elapsed 0h02m30s total-elapsed 0h02m30s\n",
            "epoch 0 batch 59/89 processed 590 batch-loss 35.9261 epoch-elapsed 0h02m34s total-elapsed 0h02m34s\n",
            "epoch 0 batch 60/89 processed 600 batch-loss 31.4409 epoch-elapsed 0h02m38s total-elapsed 0h02m38s\n",
            "epoch 0 batch 61/89 processed 610 batch-loss 36.5448 epoch-elapsed 0h02m41s total-elapsed 0h02m41s\n",
            "epoch 0 batch 62/89 processed 620 batch-loss 28.3896 epoch-elapsed 0h02m43s total-elapsed 0h02m43s\n",
            "epoch 0 batch 63/89 processed 630 batch-loss 29.8478 epoch-elapsed 0h02m46s total-elapsed 0h02m46s\n",
            "epoch 0 batch 64/89 processed 640 batch-loss 29.6014 epoch-elapsed 0h02m48s total-elapsed 0h02m48s\n",
            "epoch 0 batch 65/89 processed 650 batch-loss 25.2571 epoch-elapsed 0h02m50s total-elapsed 0h02m50s\n",
            "epoch 0 batch 66/89 processed 660 batch-loss 38.1577 epoch-elapsed 0h02m53s total-elapsed 0h02m53s\n",
            "epoch 0 batch 67/89 processed 670 batch-loss 34.0395 epoch-elapsed 0h02m56s total-elapsed 0h02m56s\n",
            "epoch 0 batch 68/89 processed 680 batch-loss 27.9227 epoch-elapsed 0h02m58s total-elapsed 0h02m58s\n",
            "epoch 0 batch 69/89 processed 690 batch-loss 33.9493 epoch-elapsed 0h03m01s total-elapsed 0h03m01s\n",
            "epoch 0 batch 70/89 processed 700 batch-loss 27.9460 epoch-elapsed 0h03m03s total-elapsed 0h03m03s\n",
            "epoch 0 batch 71/89 processed 710 batch-loss 30.2058 epoch-elapsed 0h03m05s total-elapsed 0h03m05s\n",
            "epoch 0 batch 72/89 processed 720 batch-loss 38.0758 epoch-elapsed 0h03m08s total-elapsed 0h03m08s\n",
            "epoch 0 batch 73/89 processed 730 batch-loss 37.9430 epoch-elapsed 0h03m11s total-elapsed 0h03m11s\n",
            "epoch 0 batch 74/89 processed 740 batch-loss 36.6882 epoch-elapsed 0h03m14s total-elapsed 0h03m14s\n",
            "epoch 0 batch 75/89 processed 750 batch-loss 27.3442 epoch-elapsed 0h03m16s total-elapsed 0h03m16s\n",
            "epoch 0 batch 76/89 processed 760 batch-loss 34.1801 epoch-elapsed 0h03m19s total-elapsed 0h03m19s\n",
            "epoch 0 batch 77/89 processed 770 batch-loss 30.5661 epoch-elapsed 0h03m21s total-elapsed 0h03m21s\n",
            "epoch 0 batch 78/89 processed 780 batch-loss 34.4978 epoch-elapsed 0h03m24s total-elapsed 0h03m24s\n",
            "epoch 0 batch 79/89 processed 790 batch-loss 33.4792 epoch-elapsed 0h03m27s total-elapsed 0h03m27s\n",
            "epoch 0 batch 80/89 processed 800 batch-loss 28.5032 epoch-elapsed 0h03m29s total-elapsed 0h03m29s\n",
            "epoch 0 batch 81/89 processed 810 batch-loss 27.9416 epoch-elapsed 0h03m31s total-elapsed 0h03m31s\n",
            "epoch 0 batch 82/89 processed 820 batch-loss 27.6758 epoch-elapsed 0h03m34s total-elapsed 0h03m34s\n",
            "epoch 0 batch 83/89 processed 830 batch-loss 31.3453 epoch-elapsed 0h03m36s total-elapsed 0h03m36s\n",
            "epoch 0 batch 84/89 processed 840 batch-loss 38.7027 epoch-elapsed 0h03m40s total-elapsed 0h03m40s\n",
            "epoch 0 batch 85/89 processed 850 batch-loss 35.9702 epoch-elapsed 0h03m43s total-elapsed 0h03m43s\n",
            "epoch 0 batch 86/89 processed 860 batch-loss 28.1392 epoch-elapsed 0h03m45s total-elapsed 0h03m45s\n",
            "epoch 0 batch 87/89 processed 870 batch-loss 37.4046 epoch-elapsed 0h03m48s total-elapsed 0h03m48s\n",
            "epoch 0 batch 88/89 processed 880 batch-loss 38.1143 epoch-elapsed 0h03m51s total-elapsed 0h03m51s\n",
            "epoch 0 batch 89/89 processed 886 batch-loss 30.3391 epoch-elapsed 0h03m53s total-elapsed 0h03m53s\n",
            "epoch 1 batch 1/89 processed 896 batch-loss 28.3395 epoch-elapsed 0h00m02s total-elapsed 0h03m55s\n",
            "epoch 1 batch 2/89 processed 906 batch-loss 23.6840 epoch-elapsed 0h00m04s total-elapsed 0h03m57s\n",
            "epoch 1 batch 3/89 processed 916 batch-loss 27.5122 epoch-elapsed 0h00m06s total-elapsed 0h03m59s\n",
            "epoch 1 batch 4/89 processed 926 batch-loss 38.1045 epoch-elapsed 0h00m09s total-elapsed 0h04m02s\n",
            "epoch 1 batch 5/89 processed 936 batch-loss 36.2249 epoch-elapsed 0h00m12s total-elapsed 0h04m05s\n",
            "epoch 1 batch 6/89 processed 946 batch-loss 29.0304 epoch-elapsed 0h00m14s total-elapsed 0h04m08s\n",
            "epoch 1 batch 7/89 processed 956 batch-loss 40.3905 epoch-elapsed 0h00m18s total-elapsed 0h04m11s\n",
            "epoch 1 batch 8/89 processed 966 batch-loss 35.4328 epoch-elapsed 0h00m21s total-elapsed 0h04m14s\n",
            "epoch 1 batch 9/89 processed 976 batch-loss 24.2541 epoch-elapsed 0h00m23s total-elapsed 0h04m16s\n",
            "epoch 1 batch 10/89 processed 986 batch-loss 33.1664 epoch-elapsed 0h00m26s total-elapsed 0h04m19s\n",
            "epoch 1 batch 11/89 processed 996 batch-loss 31.0988 epoch-elapsed 0h00m28s total-elapsed 0h04m21s\n",
            "epoch 1 batch 12/89 processed 1,006 batch-loss 33.8309 epoch-elapsed 0h00m31s total-elapsed 0h04m24s\n",
            "epoch 1 batch 13/89 processed 1,016 batch-loss 22.1077 epoch-elapsed 0h00m32s total-elapsed 0h04m26s\n",
            "epoch 1 batch 14/89 processed 1,026 batch-loss 30.8062 epoch-elapsed 0h00m35s total-elapsed 0h04m28s\n",
            "epoch 1 batch 15/89 processed 1,036 batch-loss 39.4448 epoch-elapsed 0h00m38s total-elapsed 0h04m32s\n",
            "epoch 1 batch 16/89 processed 1,046 batch-loss 34.7050 epoch-elapsed 0h00m41s total-elapsed 0h04m35s\n",
            "epoch 1 batch 17/89 processed 1,056 batch-loss 30.7347 epoch-elapsed 0h00m44s total-elapsed 0h04m37s\n",
            "epoch 1 batch 18/89 processed 1,066 batch-loss 27.7328 epoch-elapsed 0h00m46s total-elapsed 0h04m39s\n",
            "epoch 1 batch 19/89 processed 1,076 batch-loss 35.2621 epoch-elapsed 0h00m49s total-elapsed 0h04m42s\n",
            "epoch 1 batch 20/89 processed 1,086 batch-loss 24.1780 epoch-elapsed 0h00m50s total-elapsed 0h04m44s\n",
            "epoch 1 batch 21/89 processed 1,096 batch-loss 29.6587 epoch-elapsed 0h00m53s total-elapsed 0h04m46s\n",
            "epoch 1 batch 22/89 processed 1,106 batch-loss 36.7238 epoch-elapsed 0h00m56s total-elapsed 0h04m49s\n",
            "epoch 1 batch 23/89 processed 1,116 batch-loss 36.6390 epoch-elapsed 0h00m59s total-elapsed 0h04m52s\n",
            "epoch 1 batch 24/89 processed 1,126 batch-loss 36.9067 epoch-elapsed 0h01m02s total-elapsed 0h04m55s\n",
            "epoch 1 batch 25/89 processed 1,136 batch-loss 32.7556 epoch-elapsed 0h01m05s total-elapsed 0h04m58s\n",
            "epoch 1 batch 26/89 processed 1,146 batch-loss 30.3560 epoch-elapsed 0h01m07s total-elapsed 0h05m00s\n",
            "epoch 1 batch 27/89 processed 1,156 batch-loss 27.1050 epoch-elapsed 0h01m09s total-elapsed 0h05m02s\n",
            "epoch 1 batch 28/89 processed 1,166 batch-loss 32.3495 epoch-elapsed 0h01m12s total-elapsed 0h05m05s\n",
            "epoch 1 batch 29/89 processed 1,176 batch-loss 27.3125 epoch-elapsed 0h01m14s total-elapsed 0h05m07s\n",
            "epoch 1 batch 30/89 processed 1,186 batch-loss 29.2164 epoch-elapsed 0h01m16s total-elapsed 0h05m10s\n",
            "epoch 1 batch 31/89 processed 1,196 batch-loss 32.8955 epoch-elapsed 0h01m19s total-elapsed 0h05m12s\n",
            "epoch 1 batch 32/89 processed 1,206 batch-loss 26.1920 epoch-elapsed 0h01m21s total-elapsed 0h05m14s\n",
            "epoch 1 batch 33/89 processed 1,216 batch-loss 32.5576 epoch-elapsed 0h01m24s total-elapsed 0h05m17s\n",
            "epoch 1 batch 34/89 processed 1,226 batch-loss 41.7399 epoch-elapsed 0h01m27s total-elapsed 0h05m21s\n",
            "epoch 1 batch 35/89 processed 1,236 batch-loss 24.7546 epoch-elapsed 0h01m29s total-elapsed 0h05m23s\n",
            "epoch 1 batch 36/89 processed 1,246 batch-loss 30.5106 epoch-elapsed 0h01m32s total-elapsed 0h05m25s\n",
            "epoch 1 batch 37/89 processed 1,256 batch-loss 34.1066 epoch-elapsed 0h01m34s total-elapsed 0h05m28s\n",
            "epoch 1 batch 38/89 processed 1,266 batch-loss 25.0630 epoch-elapsed 0h01m36s total-elapsed 0h05m30s\n",
            "epoch 1 batch 39/89 processed 1,276 batch-loss 27.9930 epoch-elapsed 0h01m38s total-elapsed 0h05m32s\n",
            "epoch 1 batch 40/89 processed 1,286 batch-loss 28.8456 epoch-elapsed 0h01m41s total-elapsed 0h05m34s\n",
            "epoch 1 batch 41/89 processed 1,296 batch-loss 25.5749 epoch-elapsed 0h01m43s total-elapsed 0h05m36s\n",
            "epoch 1 batch 42/89 processed 1,306 batch-loss 25.0568 epoch-elapsed 0h01m45s total-elapsed 0h05m38s\n",
            "epoch 1 batch 43/89 processed 1,316 batch-loss 28.4532 epoch-elapsed 0h01m47s total-elapsed 0h05m40s\n",
            "epoch 1 batch 44/89 processed 1,326 batch-loss 32.7135 epoch-elapsed 0h01m50s total-elapsed 0h05m43s\n",
            "epoch 1 batch 45/89 processed 1,336 batch-loss 31.4313 epoch-elapsed 0h01m52s total-elapsed 0h05m46s\n",
            "epoch 1 batch 46/89 processed 1,346 batch-loss 20.0549 epoch-elapsed 0h01m54s total-elapsed 0h05m47s\n",
            "epoch 1 batch 47/89 processed 1,356 batch-loss 41.0613 epoch-elapsed 0h01m57s total-elapsed 0h05m51s\n",
            "epoch 1 batch 48/89 processed 1,366 batch-loss 38.8685 epoch-elapsed 0h02m00s total-elapsed 0h05m54s\n",
            "epoch 1 batch 49/89 processed 1,376 batch-loss 27.0378 epoch-elapsed 0h02m03s total-elapsed 0h05m56s\n",
            "epoch 1 batch 50/89 processed 1,386 batch-loss 26.9165 epoch-elapsed 0h02m05s total-elapsed 0h05m58s\n",
            "epoch 1 batch 51/89 processed 1,396 batch-loss 31.9204 epoch-elapsed 0h02m07s total-elapsed 0h06m01s\n",
            "epoch 1 batch 52/89 processed 1,406 batch-loss 29.5404 epoch-elapsed 0h02m10s total-elapsed 0h06m03s\n",
            "epoch 1 batch 53/89 processed 1,416 batch-loss 22.5649 epoch-elapsed 0h02m12s total-elapsed 0h06m05s\n",
            "epoch 1 batch 54/89 processed 1,426 batch-loss 25.4367 epoch-elapsed 0h02m14s total-elapsed 0h06m07s\n",
            "epoch 1 batch 55/89 processed 1,436 batch-loss 23.9159 epoch-elapsed 0h02m15s total-elapsed 0h06m09s\n",
            "epoch 1 batch 56/89 processed 1,446 batch-loss 34.2997 epoch-elapsed 0h02m18s total-elapsed 0h06m12s\n",
            "epoch 1 batch 57/89 processed 1,456 batch-loss 28.8370 epoch-elapsed 0h02m21s total-elapsed 0h06m14s\n",
            "epoch 1 batch 58/89 processed 1,466 batch-loss 33.6652 epoch-elapsed 0h02m24s total-elapsed 0h06m17s\n",
            "epoch 1 batch 59/89 processed 1,476 batch-loss 31.6706 epoch-elapsed 0h02m26s total-elapsed 0h06m20s\n",
            "epoch 1 batch 60/89 processed 1,486 batch-loss 34.4992 epoch-elapsed 0h02m29s total-elapsed 0h06m23s\n",
            "epoch 1 batch 61/89 processed 1,496 batch-loss 29.3631 epoch-elapsed 0h02m32s total-elapsed 0h06m25s\n",
            "epoch 1 batch 62/89 processed 1,506 batch-loss 36.0886 epoch-elapsed 0h02m35s total-elapsed 0h06m28s\n",
            "epoch 1 batch 63/89 processed 1,516 batch-loss 31.0622 epoch-elapsed 0h02m37s total-elapsed 0h06m31s\n",
            "epoch 1 batch 64/89 processed 1,526 batch-loss 30.0301 epoch-elapsed 0h02m40s total-elapsed 0h06m33s\n",
            "epoch 1 batch 65/89 processed 1,536 batch-loss 35.8685 epoch-elapsed 0h02m42s total-elapsed 0h06m36s\n",
            "epoch 1 batch 66/89 processed 1,546 batch-loss 34.1994 epoch-elapsed 0h02m46s total-elapsed 0h06m39s\n",
            "epoch 1 batch 67/89 processed 1,556 batch-loss 37.6235 epoch-elapsed 0h02m49s total-elapsed 0h06m42s\n",
            "epoch 1 batch 68/89 processed 1,566 batch-loss 34.5005 epoch-elapsed 0h02m52s total-elapsed 0h06m45s\n",
            "epoch 1 batch 69/89 processed 1,576 batch-loss 25.9489 epoch-elapsed 0h02m54s total-elapsed 0h06m47s\n",
            "epoch 1 batch 70/89 processed 1,586 batch-loss 47.0115 epoch-elapsed 0h03m02s total-elapsed 0h06m55s\n",
            "epoch 1 batch 71/89 processed 1,596 batch-loss 36.0976 epoch-elapsed 0h03m05s total-elapsed 0h06m58s\n",
            "epoch 1 batch 72/89 processed 1,606 batch-loss 31.0258 epoch-elapsed 0h03m07s total-elapsed 0h07m01s\n",
            "epoch 1 batch 73/89 processed 1,616 batch-loss 28.6160 epoch-elapsed 0h03m10s total-elapsed 0h07m03s\n",
            "epoch 1 batch 74/89 processed 1,626 batch-loss 33.2277 epoch-elapsed 0h03m13s total-elapsed 0h07m06s\n",
            "epoch 1 batch 75/89 processed 1,636 batch-loss 26.9990 epoch-elapsed 0h03m15s total-elapsed 0h07m08s\n",
            "epoch 1 batch 76/89 processed 1,646 batch-loss 27.3166 epoch-elapsed 0h03m17s total-elapsed 0h07m10s\n",
            "epoch 1 batch 77/89 processed 1,656 batch-loss 22.6823 epoch-elapsed 0h03m19s total-elapsed 0h07m12s\n",
            "epoch 1 batch 78/89 processed 1,666 batch-loss 35.6645 epoch-elapsed 0h03m22s total-elapsed 0h07m15s\n",
            "epoch 1 batch 79/89 processed 1,676 batch-loss 17.7671 epoch-elapsed 0h03m23s total-elapsed 0h07m17s\n",
            "epoch 1 batch 80/89 processed 1,686 batch-loss 28.1342 epoch-elapsed 0h03m26s total-elapsed 0h07m19s\n",
            "epoch 1 batch 81/89 processed 1,696 batch-loss 22.7429 epoch-elapsed 0h03m28s total-elapsed 0h07m21s\n",
            "epoch 1 batch 82/89 processed 1,706 batch-loss 32.0559 epoch-elapsed 0h03m30s total-elapsed 0h07m24s\n",
            "epoch 1 batch 83/89 processed 1,716 batch-loss 31.6495 epoch-elapsed 0h03m33s total-elapsed 0h07m26s\n",
            "epoch 1 batch 84/89 processed 1,726 batch-loss 31.6932 epoch-elapsed 0h03m36s total-elapsed 0h07m29s\n",
            "epoch 1 batch 85/89 processed 1,736 batch-loss 33.4996 epoch-elapsed 0h03m38s total-elapsed 0h07m32s\n",
            "epoch 1 batch 86/89 processed 1,746 batch-loss 29.3962 epoch-elapsed 0h03m41s total-elapsed 0h07m34s\n",
            "epoch 1 batch 87/89 processed 1,756 batch-loss 31.6935 epoch-elapsed 0h03m44s total-elapsed 0h07m37s\n",
            "epoch 1 batch 88/89 processed 1,766 batch-loss 40.6372 epoch-elapsed 0h03m48s total-elapsed 0h07m41s\n",
            "epoch 1 batch 89/89 processed 1,772 batch-loss 27.1342 epoch-elapsed 0h03m49s total-elapsed 0h07m43s\n",
            "epoch 2 batch 1/89 processed 1,782 batch-loss 27.5451 epoch-elapsed 0h00m02s total-elapsed 0h07m45s\n",
            "epoch 2 batch 2/89 processed 1,792 batch-loss 34.0141 epoch-elapsed 0h00m05s total-elapsed 0h07m48s\n",
            "epoch 2 batch 3/89 processed 1,802 batch-loss 28.8105 epoch-elapsed 0h00m07s total-elapsed 0h07m50s\n",
            "epoch 2 batch 4/89 processed 1,812 batch-loss 26.9057 epoch-elapsed 0h00m09s total-elapsed 0h07m53s\n",
            "epoch 2 batch 5/89 processed 1,822 batch-loss 20.0848 epoch-elapsed 0h00m11s total-elapsed 0h07m54s\n",
            "epoch 2 batch 6/89 processed 1,832 batch-loss 21.5323 epoch-elapsed 0h00m13s total-elapsed 0h07m56s\n",
            "epoch 2 batch 7/89 processed 1,842 batch-loss 23.2595 epoch-elapsed 0h00m15s total-elapsed 0h07m58s\n",
            "epoch 2 batch 8/89 processed 1,852 batch-loss 28.3586 epoch-elapsed 0h00m17s total-elapsed 0h08m00s\n",
            "epoch 2 batch 9/89 processed 1,862 batch-loss 29.4199 epoch-elapsed 0h00m20s total-elapsed 0h08m03s\n",
            "epoch 2 batch 10/89 processed 1,872 batch-loss 26.2451 epoch-elapsed 0h00m22s total-elapsed 0h08m05s\n",
            "epoch 2 batch 11/89 processed 1,882 batch-loss 24.9256 epoch-elapsed 0h00m24s total-elapsed 0h08m07s\n",
            "epoch 2 batch 12/89 processed 1,892 batch-loss 32.7920 epoch-elapsed 0h00m27s total-elapsed 0h08m10s\n",
            "epoch 2 batch 13/89 processed 1,902 batch-loss 34.1059 epoch-elapsed 0h00m30s total-elapsed 0h08m13s\n",
            "epoch 2 batch 14/89 processed 1,912 batch-loss 26.5433 epoch-elapsed 0h00m32s total-elapsed 0h08m15s\n",
            "epoch 2 batch 15/89 processed 1,922 batch-loss 32.1826 epoch-elapsed 0h00m35s total-elapsed 0h08m18s\n",
            "epoch 2 batch 16/89 processed 1,932 batch-loss 31.2097 epoch-elapsed 0h00m38s total-elapsed 0h08m21s\n",
            "epoch 2 batch 17/89 processed 1,942 batch-loss 30.1463 epoch-elapsed 0h00m41s total-elapsed 0h08m24s\n",
            "epoch 2 batch 18/89 processed 1,952 batch-loss 23.9151 epoch-elapsed 0h00m43s total-elapsed 0h08m26s\n",
            "epoch 2 batch 19/89 processed 1,962 batch-loss 41.1336 epoch-elapsed 0h00m47s total-elapsed 0h08m30s\n",
            "epoch 2 batch 20/89 processed 1,972 batch-loss 26.7457 epoch-elapsed 0h00m49s total-elapsed 0h08m33s\n",
            "epoch 2 batch 21/89 processed 1,982 batch-loss 31.5883 epoch-elapsed 0h00m52s total-elapsed 0h08m36s\n",
            "epoch 2 batch 22/89 processed 1,992 batch-loss 27.9190 epoch-elapsed 0h00m55s total-elapsed 0h08m38s\n",
            "epoch 2 batch 23/89 processed 2,002 batch-loss 28.5909 epoch-elapsed 0h00m57s total-elapsed 0h08m41s\n",
            "epoch 2 batch 24/89 processed 2,012 batch-loss 23.4863 epoch-elapsed 0h01m00s total-elapsed 0h08m43s\n",
            "epoch 2 batch 25/89 processed 2,022 batch-loss 36.1230 epoch-elapsed 0h01m03s total-elapsed 0h08m46s\n",
            "epoch 2 batch 26/89 processed 2,032 batch-loss 21.7935 epoch-elapsed 0h01m05s total-elapsed 0h08m48s\n",
            "epoch 2 batch 27/89 processed 2,042 batch-loss 26.4590 epoch-elapsed 0h01m08s total-elapsed 0h08m51s\n",
            "epoch 2 batch 28/89 processed 2,052 batch-loss 29.4839 epoch-elapsed 0h01m11s total-elapsed 0h08m54s\n",
            "epoch 2 batch 29/89 processed 2,062 batch-loss 32.1252 epoch-elapsed 0h01m14s total-elapsed 0h08m57s\n",
            "epoch 2 batch 30/89 processed 2,072 batch-loss 26.4812 epoch-elapsed 0h01m16s total-elapsed 0h08m59s\n",
            "epoch 2 batch 31/89 processed 2,082 batch-loss 22.1873 epoch-elapsed 0h01m18s total-elapsed 0h09m01s\n",
            "epoch 2 batch 32/89 processed 2,092 batch-loss 26.1021 epoch-elapsed 0h01m21s total-elapsed 0h09m04s\n",
            "epoch 2 batch 33/89 processed 2,102 batch-loss 23.9754 epoch-elapsed 0h01m23s total-elapsed 0h09m06s\n",
            "epoch 2 batch 34/89 processed 2,112 batch-loss 26.3753 epoch-elapsed 0h01m26s total-elapsed 0h09m09s\n",
            "epoch 2 batch 35/89 processed 2,122 batch-loss 24.5479 epoch-elapsed 0h01m28s total-elapsed 0h09m11s\n",
            "epoch 2 batch 36/89 processed 2,132 batch-loss 30.1025 epoch-elapsed 0h01m31s total-elapsed 0h09m14s\n",
            "epoch 2 batch 37/89 processed 2,142 batch-loss 32.4129 epoch-elapsed 0h01m35s total-elapsed 0h09m18s\n",
            "epoch 2 batch 38/89 processed 2,152 batch-loss 28.7982 epoch-elapsed 0h01m38s total-elapsed 0h09m21s\n",
            "epoch 2 batch 39/89 processed 2,162 batch-loss 27.3361 epoch-elapsed 0h01m40s total-elapsed 0h09m24s\n",
            "epoch 2 batch 40/89 processed 2,172 batch-loss 26.3700 epoch-elapsed 0h01m43s total-elapsed 0h09m27s\n",
            "epoch 2 batch 41/89 processed 2,182 batch-loss 27.0696 epoch-elapsed 0h01m46s total-elapsed 0h09m29s\n",
            "epoch 2 batch 42/89 processed 2,192 batch-loss 19.4146 epoch-elapsed 0h01m48s total-elapsed 0h09m31s\n",
            "epoch 2 batch 43/89 processed 2,202 batch-loss 26.2262 epoch-elapsed 0h01m51s total-elapsed 0h09m34s\n",
            "epoch 2 batch 44/89 processed 2,212 batch-loss 22.5085 epoch-elapsed 0h01m53s total-elapsed 0h09m37s\n",
            "epoch 2 batch 45/89 processed 2,222 batch-loss 28.9104 epoch-elapsed 0h01m57s total-elapsed 0h09m40s\n",
            "epoch 2 batch 46/89 processed 2,232 batch-loss 28.4344 epoch-elapsed 0h02m00s total-elapsed 0h09m43s\n",
            "epoch 2 batch 47/89 processed 2,242 batch-loss 25.5992 epoch-elapsed 0h02m02s total-elapsed 0h09m46s\n",
            "epoch 2 batch 48/89 processed 2,252 batch-loss 14.1988 epoch-elapsed 0h02m04s total-elapsed 0h09m47s\n",
            "epoch 2 batch 49/89 processed 2,262 batch-loss 25.7505 epoch-elapsed 0h02m07s total-elapsed 0h09m50s\n",
            "epoch 2 batch 50/89 processed 2,272 batch-loss 19.8838 epoch-elapsed 0h02m09s total-elapsed 0h09m52s\n",
            "epoch 2 batch 51/89 processed 2,282 batch-loss 15.6157 epoch-elapsed 0h02m11s total-elapsed 0h09m54s\n",
            "epoch 2 batch 52/89 processed 2,292 batch-loss 25.4554 epoch-elapsed 0h02m14s total-elapsed 0h09m57s\n",
            "epoch 2 batch 53/89 processed 2,302 batch-loss 21.5176 epoch-elapsed 0h02m16s total-elapsed 0h09m59s\n",
            "epoch 2 batch 54/89 processed 2,312 batch-loss 18.5951 epoch-elapsed 0h02m18s total-elapsed 0h10m01s\n",
            "epoch 2 batch 55/89 processed 2,322 batch-loss 24.0921 epoch-elapsed 0h02m21s total-elapsed 0h10m04s\n",
            "epoch 2 batch 56/89 processed 2,332 batch-loss 22.3414 epoch-elapsed 0h02m23s total-elapsed 0h10m06s\n",
            "epoch 2 batch 57/89 processed 2,342 batch-loss 26.7368 epoch-elapsed 0h02m26s total-elapsed 0h10m09s\n",
            "epoch 2 batch 58/89 processed 2,352 batch-loss 20.4292 epoch-elapsed 0h02m28s total-elapsed 0h10m11s\n",
            "epoch 2 batch 59/89 processed 2,362 batch-loss 25.3554 epoch-elapsed 0h02m31s total-elapsed 0h10m14s\n",
            "epoch 2 batch 60/89 processed 2,372 batch-loss 20.1464 epoch-elapsed 0h02m33s total-elapsed 0h10m16s\n",
            "epoch 2 batch 61/89 processed 2,382 batch-loss 24.1089 epoch-elapsed 0h02m36s total-elapsed 0h10m19s\n",
            "epoch 2 batch 62/89 processed 2,392 batch-loss 19.9795 epoch-elapsed 0h02m38s total-elapsed 0h10m21s\n",
            "epoch 2 batch 63/89 processed 2,402 batch-loss 22.2026 epoch-elapsed 0h02m41s total-elapsed 0h10m24s\n",
            "epoch 2 batch 64/89 processed 2,412 batch-loss 15.9788 epoch-elapsed 0h02m42s total-elapsed 0h10m25s\n",
            "epoch 2 batch 65/89 processed 2,422 batch-loss 33.5073 epoch-elapsed 0h02m46s total-elapsed 0h10m29s\n",
            "epoch 2 batch 66/89 processed 2,432 batch-loss 16.7477 epoch-elapsed 0h02m48s total-elapsed 0h10m31s\n",
            "epoch 2 batch 67/89 processed 2,442 batch-loss 25.6256 epoch-elapsed 0h02m50s total-elapsed 0h10m34s\n",
            "epoch 2 batch 68/89 processed 2,452 batch-loss 22.8953 epoch-elapsed 0h02m53s total-elapsed 0h10m36s\n",
            "epoch 2 batch 69/89 processed 2,462 batch-loss 19.1708 epoch-elapsed 0h02m55s total-elapsed 0h10m38s\n",
            "epoch 2 batch 70/89 processed 2,472 batch-loss 22.1606 epoch-elapsed 0h02m58s total-elapsed 0h10m41s\n",
            "epoch 2 batch 71/89 processed 2,482 batch-loss 18.8921 epoch-elapsed 0h03m00s total-elapsed 0h10m43s\n",
            "epoch 2 batch 72/89 processed 2,492 batch-loss 18.9166 epoch-elapsed 0h03m02s total-elapsed 0h10m45s\n",
            "epoch 2 batch 73/89 processed 2,502 batch-loss 25.9104 epoch-elapsed 0h03m05s total-elapsed 0h10m48s\n",
            "epoch 2 batch 74/89 processed 2,512 batch-loss 20.8750 epoch-elapsed 0h03m07s total-elapsed 0h10m51s\n",
            "epoch 2 batch 75/89 processed 2,522 batch-loss 31.4814 epoch-elapsed 0h03m11s total-elapsed 0h10m54s\n",
            "epoch 2 batch 76/89 processed 2,532 batch-loss 16.9650 epoch-elapsed 0h03m13s total-elapsed 0h10m56s\n",
            "epoch 2 batch 77/89 processed 2,542 batch-loss 21.7435 epoch-elapsed 0h03m16s total-elapsed 0h10m59s\n",
            "epoch 2 batch 78/89 processed 2,552 batch-loss 14.2167 epoch-elapsed 0h03m18s total-elapsed 0h11m01s\n",
            "epoch 2 batch 79/89 processed 2,562 batch-loss 23.6343 epoch-elapsed 0h03m20s total-elapsed 0h11m03s\n",
            "epoch 2 batch 80/89 processed 2,572 batch-loss 18.1916 epoch-elapsed 0h03m24s total-elapsed 0h11m07s\n",
            "epoch 2 batch 81/89 processed 2,582 batch-loss 22.0615 epoch-elapsed 0h03m28s total-elapsed 0h11m11s\n",
            "epoch 2 batch 82/89 processed 2,592 batch-loss 20.7740 epoch-elapsed 0h03m30s total-elapsed 0h11m14s\n",
            "epoch 2 batch 83/89 processed 2,602 batch-loss 27.2364 epoch-elapsed 0h03m34s total-elapsed 0h11m17s\n",
            "epoch 2 batch 84/89 processed 2,612 batch-loss 23.7978 epoch-elapsed 0h03m37s total-elapsed 0h11m20s\n",
            "epoch 2 batch 85/89 processed 2,622 batch-loss 20.0389 epoch-elapsed 0h03m39s total-elapsed 0h11m23s\n",
            "epoch 2 batch 86/89 processed 2,632 batch-loss 18.9605 epoch-elapsed 0h03m42s total-elapsed 0h11m25s\n",
            "epoch 2 batch 87/89 processed 2,642 batch-loss 27.4855 epoch-elapsed 0h03m46s total-elapsed 0h11m29s\n",
            "epoch 2 batch 88/89 processed 2,652 batch-loss 18.7282 epoch-elapsed 0h03m48s total-elapsed 0h11m31s\n",
            "epoch 2 batch 89/89 processed 2,658 batch-loss 21.3600 epoch-elapsed 0h03m50s total-elapsed 0h11m33s\n",
            "epoch 3 batch 1/89 processed 2,668 batch-loss 22.2550 epoch-elapsed 0h00m02s total-elapsed 0h11m36s\n",
            "epoch 3 batch 2/89 processed 2,678 batch-loss 13.2286 epoch-elapsed 0h00m04s total-elapsed 0h11m37s\n",
            "epoch 3 batch 3/89 processed 2,688 batch-loss 21.8668 epoch-elapsed 0h00m06s total-elapsed 0h11m40s\n",
            "epoch 3 batch 4/89 processed 2,698 batch-loss 17.3994 epoch-elapsed 0h00m09s total-elapsed 0h11m42s\n",
            "epoch 3 batch 5/89 processed 2,708 batch-loss 24.4849 epoch-elapsed 0h00m12s total-elapsed 0h11m45s\n",
            "epoch 3 batch 6/89 processed 2,718 batch-loss 25.3237 epoch-elapsed 0h00m15s total-elapsed 0h11m49s\n",
            "epoch 3 batch 7/89 processed 2,728 batch-loss 20.1718 epoch-elapsed 0h00m18s total-elapsed 0h11m51s\n",
            "epoch 3 batch 8/89 processed 2,738 batch-loss 16.3957 epoch-elapsed 0h00m20s total-elapsed 0h11m53s\n",
            "epoch 3 batch 9/89 processed 2,748 batch-loss 19.2464 epoch-elapsed 0h00m22s total-elapsed 0h11m56s\n",
            "epoch 3 batch 10/89 processed 2,758 batch-loss 12.9628 epoch-elapsed 0h00m24s total-elapsed 0h11m58s\n",
            "epoch 3 batch 11/89 processed 2,768 batch-loss 20.5219 epoch-elapsed 0h00m27s total-elapsed 0h12m00s\n",
            "epoch 3 batch 12/89 processed 2,778 batch-loss 16.3576 epoch-elapsed 0h00m29s total-elapsed 0h12m03s\n",
            "epoch 3 batch 13/89 processed 2,788 batch-loss 20.1896 epoch-elapsed 0h00m32s total-elapsed 0h12m06s\n",
            "epoch 3 batch 14/89 processed 2,798 batch-loss 18.3766 epoch-elapsed 0h00m34s total-elapsed 0h12m08s\n",
            "epoch 3 batch 15/89 processed 2,808 batch-loss 15.1729 epoch-elapsed 0h00m36s total-elapsed 0h12m10s\n",
            "epoch 3 batch 16/89 processed 2,818 batch-loss 16.4531 epoch-elapsed 0h00m39s total-elapsed 0h12m12s\n",
            "epoch 3 batch 17/89 processed 2,828 batch-loss 16.4165 epoch-elapsed 0h00m41s total-elapsed 0h12m14s\n",
            "epoch 3 batch 18/89 processed 2,838 batch-loss 22.6435 epoch-elapsed 0h00m44s total-elapsed 0h12m18s\n",
            "epoch 3 batch 19/89 processed 2,848 batch-loss 18.3453 epoch-elapsed 0h00m47s total-elapsed 0h12m20s\n",
            "epoch 3 batch 20/89 processed 2,858 batch-loss 21.3633 epoch-elapsed 0h00m50s total-elapsed 0h12m23s\n",
            "epoch 3 batch 21/89 processed 2,868 batch-loss 10.8909 epoch-elapsed 0h00m51s total-elapsed 0h12m25s\n",
            "epoch 3 batch 22/89 processed 2,878 batch-loss 19.1865 epoch-elapsed 0h00m54s total-elapsed 0h12m28s\n",
            "epoch 3 batch 23/89 processed 2,888 batch-loss 13.9836 epoch-elapsed 0h00m56s total-elapsed 0h12m30s\n",
            "epoch 3 batch 24/89 processed 2,898 batch-loss 20.8355 epoch-elapsed 0h00m59s total-elapsed 0h12m32s\n",
            "epoch 3 batch 25/89 processed 2,908 batch-loss 25.4334 epoch-elapsed 0h01m03s total-elapsed 0h12m36s\n",
            "epoch 3 batch 26/89 processed 2,918 batch-loss 18.8424 epoch-elapsed 0h01m06s total-elapsed 0h12m39s\n",
            "epoch 3 batch 27/89 processed 2,928 batch-loss 16.1524 epoch-elapsed 0h01m08s total-elapsed 0h12m41s\n",
            "epoch 3 batch 28/89 processed 2,938 batch-loss 12.0144 epoch-elapsed 0h01m10s total-elapsed 0h12m43s\n",
            "epoch 3 batch 29/89 processed 2,948 batch-loss 15.9693 epoch-elapsed 0h01m12s total-elapsed 0h12m46s\n",
            "epoch 3 batch 30/89 processed 2,958 batch-loss 17.0784 epoch-elapsed 0h01m15s total-elapsed 0h12m48s\n",
            "epoch 3 batch 31/89 processed 2,968 batch-loss 13.4252 epoch-elapsed 0h01m17s total-elapsed 0h12m50s\n",
            "epoch 3 batch 32/89 processed 2,978 batch-loss 21.3141 epoch-elapsed 0h01m20s total-elapsed 0h12m53s\n",
            "epoch 3 batch 33/89 processed 2,988 batch-loss 28.1509 epoch-elapsed 0h01m24s total-elapsed 0h12m57s\n",
            "epoch 3 batch 34/89 processed 2,998 batch-loss 10.4828 epoch-elapsed 0h01m25s total-elapsed 0h12m59s\n",
            "epoch 3 batch 35/89 processed 3,008 batch-loss 16.3150 epoch-elapsed 0h01m28s total-elapsed 0h13m01s\n",
            "epoch 3 batch 36/89 processed 3,018 batch-loss 16.2658 epoch-elapsed 0h01m30s total-elapsed 0h13m04s\n",
            "epoch 3 batch 37/89 processed 3,028 batch-loss 15.5246 epoch-elapsed 0h01m32s total-elapsed 0h13m06s\n",
            "epoch 3 batch 38/89 processed 3,038 batch-loss 15.7058 epoch-elapsed 0h01m35s total-elapsed 0h13m08s\n",
            "epoch 3 batch 39/89 processed 3,048 batch-loss 14.4566 epoch-elapsed 0h01m38s total-elapsed 0h13m11s\n",
            "epoch 3 batch 40/89 processed 3,058 batch-loss 14.8005 epoch-elapsed 0h01m40s total-elapsed 0h13m13s\n",
            "epoch 3 batch 41/89 processed 3,068 batch-loss 15.5662 epoch-elapsed 0h01m42s total-elapsed 0h13m16s\n",
            "epoch 3 batch 42/89 processed 3,078 batch-loss 16.8915 epoch-elapsed 0h01m45s total-elapsed 0h13m18s\n",
            "epoch 3 batch 43/89 processed 3,088 batch-loss 19.8621 epoch-elapsed 0h01m48s total-elapsed 0h13m21s\n",
            "epoch 3 batch 44/89 processed 3,098 batch-loss 18.5125 epoch-elapsed 0h01m51s total-elapsed 0h13m24s\n",
            "epoch 3 batch 45/89 processed 3,108 batch-loss 11.9952 epoch-elapsed 0h01m53s total-elapsed 0h13m26s\n",
            "epoch 3 batch 46/89 processed 3,118 batch-loss 19.6612 epoch-elapsed 0h01m56s total-elapsed 0h13m29s\n",
            "epoch 3 batch 47/89 processed 3,128 batch-loss 14.1812 epoch-elapsed 0h01m58s total-elapsed 0h13m31s\n",
            "epoch 3 batch 48/89 processed 3,138 batch-loss 12.4548 epoch-elapsed 0h02m00s total-elapsed 0h13m34s\n",
            "epoch 3 batch 49/89 processed 3,148 batch-loss 18.5678 epoch-elapsed 0h02m04s total-elapsed 0h13m37s\n",
            "epoch 3 batch 50/89 processed 3,158 batch-loss 18.6596 epoch-elapsed 0h02m06s total-elapsed 0h13m39s\n",
            "epoch 3 batch 51/89 processed 3,168 batch-loss 14.8660 epoch-elapsed 0h02m09s total-elapsed 0h13m42s\n",
            "epoch 3 batch 52/89 processed 3,178 batch-loss 12.0345 epoch-elapsed 0h02m11s total-elapsed 0h13m44s\n",
            "epoch 3 batch 53/89 processed 3,188 batch-loss 25.0787 epoch-elapsed 0h02m14s total-elapsed 0h13m48s\n",
            "epoch 3 batch 54/89 processed 3,198 batch-loss 15.2290 epoch-elapsed 0h02m17s total-elapsed 0h13m50s\n",
            "epoch 3 batch 55/89 processed 3,208 batch-loss 16.6751 epoch-elapsed 0h02m19s total-elapsed 0h13m53s\n",
            "epoch 3 batch 56/89 processed 3,218 batch-loss 14.3460 epoch-elapsed 0h02m22s total-elapsed 0h13m55s\n",
            "epoch 3 batch 57/89 processed 3,228 batch-loss 12.0736 epoch-elapsed 0h02m24s total-elapsed 0h13m57s\n",
            "epoch 3 batch 58/89 processed 3,238 batch-loss 17.3274 epoch-elapsed 0h02m27s total-elapsed 0h14m00s\n",
            "epoch 3 batch 59/89 processed 3,248 batch-loss 17.3216 epoch-elapsed 0h02m30s total-elapsed 0h14m03s\n",
            "epoch 3 batch 60/89 processed 3,258 batch-loss 17.2231 epoch-elapsed 0h02m32s total-elapsed 0h14m06s\n",
            "epoch 3 batch 61/89 processed 3,268 batch-loss 20.1149 epoch-elapsed 0h02m36s total-elapsed 0h14m09s\n",
            "epoch 3 batch 62/89 processed 3,278 batch-loss 11.5065 epoch-elapsed 0h02m38s total-elapsed 0h14m11s\n",
            "epoch 3 batch 63/89 processed 3,288 batch-loss 16.9796 epoch-elapsed 0h02m40s total-elapsed 0h14m14s\n",
            "epoch 3 batch 64/89 processed 3,298 batch-loss 21.6653 epoch-elapsed 0h02m44s total-elapsed 0h14m17s\n",
            "epoch 3 batch 65/89 processed 3,308 batch-loss 17.3707 epoch-elapsed 0h02m47s total-elapsed 0h14m20s\n",
            "epoch 3 batch 66/89 processed 3,318 batch-loss 15.2134 epoch-elapsed 0h02m49s total-elapsed 0h14m22s\n",
            "epoch 3 batch 67/89 processed 3,328 batch-loss 13.8823 epoch-elapsed 0h02m51s total-elapsed 0h14m24s\n",
            "epoch 3 batch 68/89 processed 3,338 batch-loss 16.5658 epoch-elapsed 0h02m54s total-elapsed 0h14m27s\n",
            "epoch 3 batch 69/89 processed 3,348 batch-loss 13.4901 epoch-elapsed 0h02m56s total-elapsed 0h14m29s\n",
            "epoch 3 batch 70/89 processed 3,358 batch-loss 15.5944 epoch-elapsed 0h02m59s total-elapsed 0h14m32s\n",
            "epoch 3 batch 71/89 processed 3,368 batch-loss 16.8556 epoch-elapsed 0h03m01s total-elapsed 0h14m35s\n",
            "epoch 3 batch 72/89 processed 3,378 batch-loss 17.1826 epoch-elapsed 0h03m05s total-elapsed 0h14m38s\n",
            "epoch 3 batch 73/89 processed 3,388 batch-loss 10.2487 epoch-elapsed 0h03m07s total-elapsed 0h14m40s\n",
            "epoch 3 batch 74/89 processed 3,398 batch-loss 13.1275 epoch-elapsed 0h03m10s total-elapsed 0h14m43s\n",
            "epoch 3 batch 75/89 processed 3,408 batch-loss 13.8502 epoch-elapsed 0h03m12s total-elapsed 0h14m46s\n",
            "epoch 3 batch 76/89 processed 3,418 batch-loss 11.2791 epoch-elapsed 0h03m14s total-elapsed 0h14m48s\n",
            "epoch 3 batch 77/89 processed 3,428 batch-loss 8.8948 epoch-elapsed 0h03m16s total-elapsed 0h14m49s\n",
            "epoch 3 batch 78/89 processed 3,438 batch-loss 15.1639 epoch-elapsed 0h03m18s total-elapsed 0h14m52s\n",
            "epoch 3 batch 79/89 processed 3,448 batch-loss 16.4647 epoch-elapsed 0h03m21s total-elapsed 0h14m54s\n",
            "epoch 3 batch 80/89 processed 3,458 batch-loss 20.6117 epoch-elapsed 0h03m24s total-elapsed 0h14m58s\n",
            "epoch 3 batch 81/89 processed 3,468 batch-loss 10.0945 epoch-elapsed 0h03m26s total-elapsed 0h14m59s\n",
            "epoch 3 batch 82/89 processed 3,478 batch-loss 15.4187 epoch-elapsed 0h03m28s total-elapsed 0h15m02s\n",
            "epoch 3 batch 83/89 processed 3,488 batch-loss 9.3208 epoch-elapsed 0h03m31s total-elapsed 0h15m04s\n",
            "epoch 3 batch 84/89 processed 3,498 batch-loss 13.5448 epoch-elapsed 0h03m33s total-elapsed 0h15m06s\n",
            "epoch 3 batch 85/89 processed 3,508 batch-loss 17.9245 epoch-elapsed 0h03m36s total-elapsed 0h15m10s\n",
            "epoch 3 batch 86/89 processed 3,518 batch-loss 16.9555 epoch-elapsed 0h03m39s total-elapsed 0h15m13s\n",
            "epoch 3 batch 87/89 processed 3,528 batch-loss 8.8477 epoch-elapsed 0h03m41s total-elapsed 0h15m15s\n",
            "epoch 3 batch 88/89 processed 3,538 batch-loss 18.6618 epoch-elapsed 0h03m45s total-elapsed 0h15m18s\n",
            "epoch 3 batch 89/89 processed 3,544 batch-loss 8.3408 epoch-elapsed 0h03m46s total-elapsed 0h15m19s\n",
            "epoch 4 batch 1/89 processed 3,554 batch-loss 14.2904 epoch-elapsed 0h00m02s total-elapsed 0h15m22s\n",
            "epoch 4 batch 2/89 processed 3,564 batch-loss 16.5575 epoch-elapsed 0h00m05s total-elapsed 0h15m25s\n",
            "epoch 4 batch 3/89 processed 3,574 batch-loss 10.9807 epoch-elapsed 0h00m07s total-elapsed 0h15m27s\n",
            "epoch 4 batch 4/89 processed 3,584 batch-loss 19.5558 epoch-elapsed 0h00m13s total-elapsed 0h15m33s\n",
            "epoch 4 batch 5/89 processed 3,594 batch-loss 13.6733 epoch-elapsed 0h00m17s total-elapsed 0h15m37s\n",
            "epoch 4 batch 6/89 processed 3,604 batch-loss 10.3653 epoch-elapsed 0h00m19s total-elapsed 0h15m39s\n",
            "epoch 4 batch 7/89 processed 3,614 batch-loss 11.5694 epoch-elapsed 0h00m21s total-elapsed 0h15m41s\n",
            "epoch 4 batch 8/89 processed 3,624 batch-loss 20.9866 epoch-elapsed 0h00m25s total-elapsed 0h15m45s\n",
            "epoch 4 batch 9/89 processed 3,634 batch-loss 10.2639 epoch-elapsed 0h00m27s total-elapsed 0h15m47s\n",
            "epoch 4 batch 10/89 processed 3,644 batch-loss 9.8497 epoch-elapsed 0h00m29s total-elapsed 0h15m49s\n",
            "epoch 4 batch 11/89 processed 3,654 batch-loss 11.4071 epoch-elapsed 0h00m31s total-elapsed 0h15m51s\n",
            "epoch 4 batch 12/89 processed 3,664 batch-loss 9.1930 epoch-elapsed 0h00m33s total-elapsed 0h15m53s\n",
            "epoch 4 batch 13/89 processed 3,674 batch-loss 16.5322 epoch-elapsed 0h00m36s total-elapsed 0h15m55s\n",
            "epoch 4 batch 14/89 processed 3,684 batch-loss 13.5134 epoch-elapsed 0h00m38s total-elapsed 0h15m58s\n",
            "epoch 4 batch 15/89 processed 3,694 batch-loss 9.3750 epoch-elapsed 0h00m40s total-elapsed 0h16m00s\n",
            "epoch 4 batch 16/89 processed 3,704 batch-loss 18.2193 epoch-elapsed 0h00m44s total-elapsed 0h16m03s\n",
            "epoch 4 batch 17/89 processed 3,714 batch-loss 12.2529 epoch-elapsed 0h00m46s total-elapsed 0h16m06s\n",
            "epoch 4 batch 18/89 processed 3,724 batch-loss 9.6854 epoch-elapsed 0h00m48s total-elapsed 0h16m08s\n",
            "epoch 4 batch 19/89 processed 3,734 batch-loss 13.9042 epoch-elapsed 0h00m51s total-elapsed 0h16m11s\n",
            "epoch 4 batch 20/89 processed 3,744 batch-loss 7.4073 epoch-elapsed 0h00m53s total-elapsed 0h16m13s\n",
            "epoch 4 batch 21/89 processed 3,754 batch-loss 19.2488 epoch-elapsed 0h00m56s total-elapsed 0h16m15s\n",
            "epoch 4 batch 22/89 processed 3,764 batch-loss 15.8450 epoch-elapsed 0h00m59s total-elapsed 0h16m19s\n",
            "epoch 4 batch 23/89 processed 3,774 batch-loss 11.7874 epoch-elapsed 0h01m02s total-elapsed 0h16m22s\n",
            "epoch 4 batch 24/89 processed 3,784 batch-loss 12.7261 epoch-elapsed 0h01m05s total-elapsed 0h16m24s\n",
            "epoch 4 batch 25/89 processed 3,794 batch-loss 11.0077 epoch-elapsed 0h01m07s total-elapsed 0h16m26s\n",
            "epoch 4 batch 26/89 processed 3,804 batch-loss 18.3755 epoch-elapsed 0h01m11s total-elapsed 0h16m30s\n",
            "epoch 4 batch 27/89 processed 3,814 batch-loss 13.4305 epoch-elapsed 0h01m13s total-elapsed 0h16m33s\n",
            "epoch 4 batch 28/89 processed 3,824 batch-loss 20.8942 epoch-elapsed 0h01m16s total-elapsed 0h16m36s\n",
            "epoch 4 batch 29/89 processed 3,834 batch-loss 15.4644 epoch-elapsed 0h01m19s total-elapsed 0h16m39s\n",
            "epoch 4 batch 30/89 processed 3,844 batch-loss 6.6543 epoch-elapsed 0h01m21s total-elapsed 0h16m40s\n",
            "epoch 4 batch 31/89 processed 3,854 batch-loss 12.7970 epoch-elapsed 0h01m23s total-elapsed 0h16m43s\n",
            "epoch 4 batch 32/89 processed 3,864 batch-loss 11.1169 epoch-elapsed 0h01m25s total-elapsed 0h16m45s\n",
            "epoch 4 batch 33/89 processed 3,874 batch-loss 13.7200 epoch-elapsed 0h01m28s total-elapsed 0h16m48s\n",
            "epoch 4 batch 34/89 processed 3,884 batch-loss 9.4147 epoch-elapsed 0h01m30s total-elapsed 0h16m49s\n",
            "epoch 4 batch 35/89 processed 3,894 batch-loss 9.3496 epoch-elapsed 0h01m31s total-elapsed 0h16m51s\n",
            "epoch 4 batch 36/89 processed 3,904 batch-loss 14.9510 epoch-elapsed 0h01m34s total-elapsed 0h16m54s\n",
            "epoch 4 batch 37/89 processed 3,914 batch-loss 15.0452 epoch-elapsed 0h01m37s total-elapsed 0h16m56s\n",
            "epoch 4 batch 38/89 processed 3,924 batch-loss 17.7152 epoch-elapsed 0h01m40s total-elapsed 0h16m59s\n",
            "epoch 4 batch 39/89 processed 3,934 batch-loss 14.6872 epoch-elapsed 0h01m42s total-elapsed 0h17m02s\n",
            "epoch 4 batch 40/89 processed 3,944 batch-loss 15.0538 epoch-elapsed 0h01m45s total-elapsed 0h17m05s\n",
            "epoch 4 batch 41/89 processed 3,954 batch-loss 12.6842 epoch-elapsed 0h01m48s total-elapsed 0h17m07s\n",
            "epoch 4 batch 42/89 processed 3,964 batch-loss 8.7203 epoch-elapsed 0h01m49s total-elapsed 0h17m09s\n",
            "epoch 4 batch 43/89 processed 3,974 batch-loss 14.8173 epoch-elapsed 0h01m52s total-elapsed 0h17m11s\n",
            "epoch 4 batch 44/89 processed 3,984 batch-loss 12.3377 epoch-elapsed 0h01m54s total-elapsed 0h17m14s\n",
            "epoch 4 batch 45/89 processed 3,994 batch-loss 16.3950 epoch-elapsed 0h01m57s total-elapsed 0h17m17s\n",
            "epoch 4 batch 46/89 processed 4,004 batch-loss 13.0352 epoch-elapsed 0h02m00s total-elapsed 0h17m20s\n",
            "epoch 4 batch 47/89 processed 4,014 batch-loss 13.7206 epoch-elapsed 0h02m03s total-elapsed 0h17m22s\n",
            "epoch 4 batch 48/89 processed 4,024 batch-loss 8.8339 epoch-elapsed 0h02m05s total-elapsed 0h17m24s\n",
            "epoch 4 batch 49/89 processed 4,034 batch-loss 8.3711 epoch-elapsed 0h02m07s total-elapsed 0h17m26s\n",
            "epoch 4 batch 50/89 processed 4,044 batch-loss 15.8202 epoch-elapsed 0h02m10s total-elapsed 0h17m29s\n",
            "epoch 4 batch 51/89 processed 4,054 batch-loss 17.5601 epoch-elapsed 0h02m13s total-elapsed 0h17m32s\n",
            "epoch 4 batch 52/89 processed 4,064 batch-loss 15.4951 epoch-elapsed 0h02m15s total-elapsed 0h17m35s\n",
            "epoch 4 batch 53/89 processed 4,074 batch-loss 11.6479 epoch-elapsed 0h02m18s total-elapsed 0h17m37s\n",
            "epoch 4 batch 54/89 processed 4,084 batch-loss 13.6034 epoch-elapsed 0h02m20s total-elapsed 0h17m40s\n",
            "epoch 4 batch 55/89 processed 4,094 batch-loss 23.2170 epoch-elapsed 0h02m24s total-elapsed 0h17m44s\n",
            "epoch 4 batch 56/89 processed 4,104 batch-loss 9.9264 epoch-elapsed 0h02m26s total-elapsed 0h17m46s\n",
            "epoch 4 batch 57/89 processed 4,114 batch-loss 12.2503 epoch-elapsed 0h02m28s total-elapsed 0h17m48s\n",
            "epoch 4 batch 58/89 processed 4,124 batch-loss 5.9413 epoch-elapsed 0h02m30s total-elapsed 0h17m49s\n",
            "epoch 4 batch 59/89 processed 4,134 batch-loss 18.2765 epoch-elapsed 0h02m34s total-elapsed 0h17m53s\n",
            "epoch 4 batch 60/89 processed 4,144 batch-loss 9.3531 epoch-elapsed 0h02m36s total-elapsed 0h17m55s\n",
            "epoch 4 batch 61/89 processed 4,154 batch-loss 13.1237 epoch-elapsed 0h02m38s total-elapsed 0h17m58s\n",
            "epoch 4 batch 62/89 processed 4,164 batch-loss 10.9543 epoch-elapsed 0h02m41s total-elapsed 0h18m01s\n",
            "epoch 4 batch 63/89 processed 4,174 batch-loss 11.9169 epoch-elapsed 0h02m44s total-elapsed 0h18m03s\n",
            "epoch 4 batch 64/89 processed 4,184 batch-loss 7.1921 epoch-elapsed 0h02m45s total-elapsed 0h18m05s\n",
            "epoch 4 batch 65/89 processed 4,194 batch-loss 16.8067 epoch-elapsed 0h02m48s total-elapsed 0h18m08s\n",
            "epoch 4 batch 66/89 processed 4,204 batch-loss 16.2490 epoch-elapsed 0h02m51s total-elapsed 0h18m11s\n",
            "epoch 4 batch 67/89 processed 4,214 batch-loss 17.6431 epoch-elapsed 0h02m55s total-elapsed 0h18m15s\n",
            "epoch 4 batch 68/89 processed 4,224 batch-loss 12.8609 epoch-elapsed 0h02m57s total-elapsed 0h18m17s\n",
            "epoch 4 batch 69/89 processed 4,234 batch-loss 14.7794 epoch-elapsed 0h03m00s total-elapsed 0h18m20s\n",
            "epoch 4 batch 70/89 processed 4,244 batch-loss 12.6096 epoch-elapsed 0h03m02s total-elapsed 0h18m22s\n",
            "epoch 4 batch 71/89 processed 4,254 batch-loss 11.6410 epoch-elapsed 0h03m04s total-elapsed 0h18m24s\n",
            "epoch 4 batch 72/89 processed 4,264 batch-loss 13.0322 epoch-elapsed 0h03m07s total-elapsed 0h18m27s\n",
            "epoch 4 batch 73/89 processed 4,274 batch-loss 16.5299 epoch-elapsed 0h03m10s total-elapsed 0h18m29s\n",
            "epoch 4 batch 74/89 processed 4,284 batch-loss 12.3538 epoch-elapsed 0h03m13s total-elapsed 0h18m32s\n",
            "epoch 4 batch 75/89 processed 4,294 batch-loss 12.9796 epoch-elapsed 0h03m16s total-elapsed 0h18m36s\n",
            "epoch 4 batch 76/89 processed 4,304 batch-loss 9.3603 epoch-elapsed 0h03m18s total-elapsed 0h18m37s\n",
            "epoch 4 batch 77/89 processed 4,314 batch-loss 9.2701 epoch-elapsed 0h03m20s total-elapsed 0h18m39s\n",
            "epoch 4 batch 78/89 processed 4,324 batch-loss 11.0026 epoch-elapsed 0h03m22s total-elapsed 0h18m42s\n",
            "epoch 4 batch 79/89 processed 4,334 batch-loss 10.6172 epoch-elapsed 0h03m24s total-elapsed 0h18m44s\n",
            "epoch 4 batch 80/89 processed 4,344 batch-loss 15.8509 epoch-elapsed 0h03m27s total-elapsed 0h18m47s\n",
            "epoch 4 batch 81/89 processed 4,354 batch-loss 12.8538 epoch-elapsed 0h03m30s total-elapsed 0h18m50s\n",
            "epoch 4 batch 82/89 processed 4,364 batch-loss 12.7640 epoch-elapsed 0h03m32s total-elapsed 0h18m52s\n",
            "epoch 4 batch 83/89 processed 4,374 batch-loss 13.8284 epoch-elapsed 0h03m35s total-elapsed 0h18m54s\n",
            "epoch 4 batch 84/89 processed 4,384 batch-loss 16.7026 epoch-elapsed 0h03m38s total-elapsed 0h18m57s\n",
            "epoch 4 batch 85/89 processed 4,394 batch-loss 17.7780 epoch-elapsed 0h03m41s total-elapsed 0h19m01s\n",
            "epoch 4 batch 86/89 processed 4,404 batch-loss 11.5433 epoch-elapsed 0h03m44s total-elapsed 0h19m03s\n",
            "epoch 4 batch 87/89 processed 4,414 batch-loss 9.2685 epoch-elapsed 0h03m46s total-elapsed 0h19m06s\n",
            "epoch 4 batch 88/89 processed 4,424 batch-loss 8.1142 epoch-elapsed 0h03m48s total-elapsed 0h19m08s\n",
            "epoch 4 batch 89/89 processed 4,430 batch-loss 12.8807 epoch-elapsed 0h03m50s total-elapsed 0h19m09s\n",
            "epoch 5 batch 1/89 processed 4,440 batch-loss 12.5431 epoch-elapsed 0h00m02s total-elapsed 0h19m12s\n",
            "epoch 5 batch 2/89 processed 4,450 batch-loss 6.4759 epoch-elapsed 0h00m04s total-elapsed 0h19m14s\n",
            "epoch 5 batch 3/89 processed 4,460 batch-loss 5.9341 epoch-elapsed 0h00m06s total-elapsed 0h19m16s\n",
            "epoch 5 batch 4/89 processed 4,470 batch-loss 11.8560 epoch-elapsed 0h00m08s total-elapsed 0h19m18s\n",
            "epoch 5 batch 5/89 processed 4,480 batch-loss 7.1626 epoch-elapsed 0h00m10s total-elapsed 0h19m20s\n",
            "epoch 5 batch 6/89 processed 4,490 batch-loss 14.5493 epoch-elapsed 0h00m14s total-elapsed 0h19m23s\n",
            "epoch 5 batch 7/89 processed 4,500 batch-loss 12.3356 epoch-elapsed 0h00m16s total-elapsed 0h19m26s\n",
            "epoch 5 batch 8/89 processed 4,510 batch-loss 13.4487 epoch-elapsed 0h00m19s total-elapsed 0h19m29s\n",
            "epoch 5 batch 9/89 processed 4,520 batch-loss 13.6669 epoch-elapsed 0h00m23s total-elapsed 0h19m32s\n",
            "epoch 5 batch 10/89 processed 4,530 batch-loss 17.3309 epoch-elapsed 0h00m26s total-elapsed 0h19m36s\n",
            "epoch 5 batch 11/89 processed 4,540 batch-loss 9.9291 epoch-elapsed 0h00m29s total-elapsed 0h19m39s\n",
            "epoch 5 batch 12/89 processed 4,550 batch-loss 15.2035 epoch-elapsed 0h00m32s total-elapsed 0h19m42s\n",
            "epoch 5 batch 13/89 processed 4,560 batch-loss 14.6072 epoch-elapsed 0h00m35s total-elapsed 0h19m44s\n",
            "epoch 5 batch 14/89 processed 4,570 batch-loss 11.5505 epoch-elapsed 0h00m37s total-elapsed 0h19m47s\n",
            "epoch 5 batch 15/89 processed 4,580 batch-loss 16.6283 epoch-elapsed 0h00m40s total-elapsed 0h19m50s\n",
            "epoch 5 batch 16/89 processed 4,590 batch-loss 12.6133 epoch-elapsed 0h00m45s total-elapsed 0h19m55s\n",
            "epoch 5 batch 17/89 processed 4,600 batch-loss 11.7472 epoch-elapsed 0h00m49s total-elapsed 0h19m58s\n",
            "epoch 5 batch 18/89 processed 4,610 batch-loss 13.7036 epoch-elapsed 0h00m51s total-elapsed 0h20m01s\n",
            "epoch 5 batch 19/89 processed 4,620 batch-loss 13.1254 epoch-elapsed 0h00m54s total-elapsed 0h20m04s\n",
            "epoch 5 batch 20/89 processed 4,630 batch-loss 9.4886 epoch-elapsed 0h00m56s total-elapsed 0h20m06s\n",
            "epoch 5 batch 21/89 processed 4,640 batch-loss 7.9093 epoch-elapsed 0h00m58s total-elapsed 0h20m08s\n",
            "epoch 5 batch 22/89 processed 4,650 batch-loss 8.4641 epoch-elapsed 0h01m00s total-elapsed 0h20m10s\n",
            "epoch 5 batch 23/89 processed 4,660 batch-loss 10.1238 epoch-elapsed 0h01m03s total-elapsed 0h20m12s\n",
            "epoch 5 batch 24/89 processed 4,670 batch-loss 9.5859 epoch-elapsed 0h01m05s total-elapsed 0h20m15s\n",
            "epoch 5 batch 25/89 processed 4,680 batch-loss 13.6137 epoch-elapsed 0h01m08s total-elapsed 0h20m17s\n",
            "epoch 5 batch 26/89 processed 4,690 batch-loss 8.0797 epoch-elapsed 0h01m10s total-elapsed 0h20m20s\n",
            "epoch 5 batch 27/89 processed 4,700 batch-loss 12.7932 epoch-elapsed 0h01m12s total-elapsed 0h20m22s\n",
            "epoch 5 batch 28/89 processed 4,710 batch-loss 10.9464 epoch-elapsed 0h01m15s total-elapsed 0h20m24s\n",
            "epoch 5 batch 29/89 processed 4,720 batch-loss 12.4980 epoch-elapsed 0h01m17s total-elapsed 0h20m27s\n",
            "epoch 5 batch 30/89 processed 4,730 batch-loss 11.8632 epoch-elapsed 0h01m20s total-elapsed 0h20m30s\n",
            "epoch 5 batch 31/89 processed 4,740 batch-loss 7.7855 epoch-elapsed 0h01m22s total-elapsed 0h20m32s\n",
            "epoch 5 batch 32/89 processed 4,750 batch-loss 11.5354 epoch-elapsed 0h01m25s total-elapsed 0h20m34s\n",
            "epoch 5 batch 33/89 processed 4,760 batch-loss 13.2547 epoch-elapsed 0h01m27s total-elapsed 0h20m37s\n",
            "epoch 5 batch 34/89 processed 4,770 batch-loss 9.2882 epoch-elapsed 0h01m30s total-elapsed 0h20m40s\n",
            "epoch 5 batch 35/89 processed 4,780 batch-loss 12.2205 epoch-elapsed 0h01m32s total-elapsed 0h20m42s\n",
            "epoch 5 batch 36/89 processed 4,790 batch-loss 21.4567 epoch-elapsed 0h01m36s total-elapsed 0h20m46s\n",
            "epoch 5 batch 37/89 processed 4,800 batch-loss 11.6330 epoch-elapsed 0h01m39s total-elapsed 0h20m48s\n",
            "epoch 5 batch 38/89 processed 4,810 batch-loss 10.6525 epoch-elapsed 0h01m41s total-elapsed 0h20m51s\n",
            "epoch 5 batch 39/89 processed 4,820 batch-loss 9.6159 epoch-elapsed 0h01m43s total-elapsed 0h20m53s\n",
            "epoch 5 batch 40/89 processed 4,830 batch-loss 11.6011 epoch-elapsed 0h01m46s total-elapsed 0h20m55s\n",
            "epoch 5 batch 41/89 processed 4,840 batch-loss 12.1192 epoch-elapsed 0h01m48s total-elapsed 0h20m58s\n",
            "epoch 5 batch 42/89 processed 4,850 batch-loss 11.3868 epoch-elapsed 0h01m51s total-elapsed 0h21m01s\n",
            "epoch 5 batch 43/89 processed 4,860 batch-loss 13.7055 epoch-elapsed 0h01m54s total-elapsed 0h21m04s\n",
            "epoch 5 batch 44/89 processed 4,870 batch-loss 11.6264 epoch-elapsed 0h01m57s total-elapsed 0h21m07s\n",
            "epoch 5 batch 45/89 processed 4,880 batch-loss 6.7683 epoch-elapsed 0h01m59s total-elapsed 0h21m09s\n",
            "epoch 5 batch 46/89 processed 4,890 batch-loss 16.2612 epoch-elapsed 0h02m02s total-elapsed 0h21m12s\n",
            "epoch 5 batch 47/89 processed 4,900 batch-loss 11.0223 epoch-elapsed 0h02m04s total-elapsed 0h21m14s\n",
            "epoch 5 batch 48/89 processed 4,910 batch-loss 14.7460 epoch-elapsed 0h02m07s total-elapsed 0h21m17s\n",
            "epoch 5 batch 49/89 processed 4,920 batch-loss 11.8900 epoch-elapsed 0h02m10s total-elapsed 0h21m19s\n",
            "epoch 5 batch 50/89 processed 4,930 batch-loss 7.5002 epoch-elapsed 0h02m11s total-elapsed 0h21m21s\n",
            "epoch 5 batch 51/89 processed 4,940 batch-loss 9.3763 epoch-elapsed 0h02m14s total-elapsed 0h21m23s\n",
            "epoch 5 batch 52/89 processed 4,950 batch-loss 9.3146 epoch-elapsed 0h02m16s total-elapsed 0h21m26s\n",
            "epoch 5 batch 53/89 processed 4,960 batch-loss 14.4180 epoch-elapsed 0h02m19s total-elapsed 0h21m29s\n",
            "epoch 5 batch 54/89 processed 4,970 batch-loss 12.9540 epoch-elapsed 0h02m23s total-elapsed 0h21m32s\n",
            "epoch 5 batch 55/89 processed 4,980 batch-loss 13.7770 epoch-elapsed 0h02m26s total-elapsed 0h21m35s\n",
            "epoch 5 batch 56/89 processed 4,990 batch-loss 10.0494 epoch-elapsed 0h02m28s total-elapsed 0h21m38s\n",
            "epoch 5 batch 57/89 processed 5,000 batch-loss 8.0194 epoch-elapsed 0h02m30s total-elapsed 0h21m40s\n",
            "epoch 5 batch 58/89 processed 5,010 batch-loss 10.8814 epoch-elapsed 0h02m32s total-elapsed 0h21m42s\n",
            "epoch 5 batch 59/89 processed 5,020 batch-loss 10.6944 epoch-elapsed 0h02m35s total-elapsed 0h21m45s\n",
            "epoch 5 batch 60/89 processed 5,030 batch-loss 13.9547 epoch-elapsed 0h02m38s total-elapsed 0h21m48s\n",
            "epoch 5 batch 61/89 processed 5,040 batch-loss 12.4860 epoch-elapsed 0h02m40s total-elapsed 0h21m50s\n",
            "epoch 5 batch 62/89 processed 5,050 batch-loss 11.7537 epoch-elapsed 0h02m43s total-elapsed 0h21m52s\n",
            "epoch 5 batch 63/89 processed 5,060 batch-loss 11.6663 epoch-elapsed 0h02m45s total-elapsed 0h21m55s\n",
            "epoch 5 batch 64/89 processed 5,070 batch-loss 9.8157 epoch-elapsed 0h02m48s total-elapsed 0h21m57s\n",
            "epoch 5 batch 65/89 processed 5,080 batch-loss 9.9569 epoch-elapsed 0h02m50s total-elapsed 0h21m59s\n",
            "epoch 5 batch 66/89 processed 5,090 batch-loss 7.6923 epoch-elapsed 0h02m51s total-elapsed 0h22m01s\n",
            "epoch 5 batch 67/89 processed 5,100 batch-loss 14.8262 epoch-elapsed 0h02m54s total-elapsed 0h22m04s\n",
            "epoch 5 batch 68/89 processed 5,110 batch-loss 7.9791 epoch-elapsed 0h02m56s total-elapsed 0h22m06s\n",
            "epoch 5 batch 69/89 processed 5,120 batch-loss 14.7905 epoch-elapsed 0h02m59s total-elapsed 0h22m09s\n",
            "epoch 5 batch 70/89 processed 5,130 batch-loss 12.0845 epoch-elapsed 0h03m02s total-elapsed 0h22m11s\n",
            "epoch 5 batch 71/89 processed 5,140 batch-loss 12.7277 epoch-elapsed 0h03m04s total-elapsed 0h22m14s\n",
            "epoch 5 batch 72/89 processed 5,150 batch-loss 10.8162 epoch-elapsed 0h03m06s total-elapsed 0h22m16s\n",
            "epoch 5 batch 73/89 processed 5,160 batch-loss 10.7333 epoch-elapsed 0h03m09s total-elapsed 0h22m19s\n",
            "epoch 5 batch 74/89 processed 5,170 batch-loss 9.7021 epoch-elapsed 0h03m11s total-elapsed 0h22m21s\n",
            "epoch 5 batch 75/89 processed 5,180 batch-loss 10.8115 epoch-elapsed 0h03m13s total-elapsed 0h22m23s\n",
            "epoch 5 batch 76/89 processed 5,190 batch-loss 13.7633 epoch-elapsed 0h03m16s total-elapsed 0h22m26s\n",
            "epoch 5 batch 77/89 processed 5,200 batch-loss 12.9429 epoch-elapsed 0h03m19s total-elapsed 0h22m28s\n",
            "epoch 5 batch 78/89 processed 5,210 batch-loss 13.0673 epoch-elapsed 0h03m22s total-elapsed 0h22m31s\n",
            "epoch 5 batch 79/89 processed 5,220 batch-loss 12.4018 epoch-elapsed 0h03m24s total-elapsed 0h22m34s\n",
            "epoch 5 batch 80/89 processed 5,230 batch-loss 9.5580 epoch-elapsed 0h03m26s total-elapsed 0h22m36s\n",
            "epoch 5 batch 81/89 processed 5,240 batch-loss 14.8707 epoch-elapsed 0h03m29s total-elapsed 0h22m39s\n",
            "epoch 5 batch 82/89 processed 5,250 batch-loss 11.2870 epoch-elapsed 0h03m32s total-elapsed 0h22m42s\n",
            "epoch 5 batch 83/89 processed 5,260 batch-loss 13.0825 epoch-elapsed 0h03m35s total-elapsed 0h22m45s\n",
            "epoch 5 batch 84/89 processed 5,270 batch-loss 10.5264 epoch-elapsed 0h03m38s total-elapsed 0h22m47s\n",
            "epoch 5 batch 85/89 processed 5,280 batch-loss 10.7163 epoch-elapsed 0h03m40s total-elapsed 0h22m50s\n",
            "epoch 5 batch 86/89 processed 5,290 batch-loss 9.1389 epoch-elapsed 0h03m43s total-elapsed 0h22m52s\n",
            "epoch 5 batch 87/89 processed 5,300 batch-loss 14.9005 epoch-elapsed 0h03m46s total-elapsed 0h22m55s\n",
            "epoch 5 batch 88/89 processed 5,310 batch-loss 6.5925 epoch-elapsed 0h03m47s total-elapsed 0h22m57s\n",
            "epoch 5 batch 89/89 processed 5,316 batch-loss 8.9864 epoch-elapsed 0h03m49s total-elapsed 0h22m59s\n",
            "epoch 6 batch 1/89 processed 5,326 batch-loss 5.6271 epoch-elapsed 0h00m01s total-elapsed 0h23m00s\n",
            "epoch 6 batch 2/89 processed 5,336 batch-loss 7.3925 epoch-elapsed 0h00m03s total-elapsed 0h23m03s\n",
            "epoch 6 batch 3/89 processed 5,346 batch-loss 9.8219 epoch-elapsed 0h00m05s total-elapsed 0h23m04s\n",
            "epoch 6 batch 4/89 processed 5,356 batch-loss 7.6361 epoch-elapsed 0h00m07s total-elapsed 0h23m06s\n",
            "epoch 6 batch 5/89 processed 5,366 batch-loss 11.3218 epoch-elapsed 0h00m10s total-elapsed 0h23m09s\n",
            "epoch 6 batch 6/89 processed 5,376 batch-loss 10.1292 epoch-elapsed 0h00m13s total-elapsed 0h23m12s\n",
            "epoch 6 batch 7/89 processed 5,386 batch-loss 8.1353 epoch-elapsed 0h00m15s total-elapsed 0h23m14s\n",
            "epoch 6 batch 8/89 processed 5,396 batch-loss 7.3198 epoch-elapsed 0h00m18s total-elapsed 0h23m17s\n",
            "epoch 6 batch 9/89 processed 5,406 batch-loss 7.1153 epoch-elapsed 0h00m20s total-elapsed 0h23m19s\n",
            "epoch 6 batch 10/89 processed 5,416 batch-loss 10.9504 epoch-elapsed 0h00m22s total-elapsed 0h23m22s\n",
            "epoch 6 batch 11/89 processed 5,426 batch-loss 7.4736 epoch-elapsed 0h00m24s total-elapsed 0h23m23s\n",
            "epoch 6 batch 12/89 processed 5,436 batch-loss 10.4061 epoch-elapsed 0h00m27s total-elapsed 0h23m26s\n",
            "epoch 6 batch 13/89 processed 5,446 batch-loss 7.2431 epoch-elapsed 0h00m29s total-elapsed 0h23m28s\n",
            "epoch 6 batch 14/89 processed 5,456 batch-loss 7.8742 epoch-elapsed 0h00m31s total-elapsed 0h23m30s\n",
            "epoch 6 batch 15/89 processed 5,466 batch-loss 8.1949 epoch-elapsed 0h00m33s total-elapsed 0h23m32s\n",
            "epoch 6 batch 16/89 processed 5,476 batch-loss 14.0003 epoch-elapsed 0h00m36s total-elapsed 0h23m35s\n",
            "epoch 6 batch 17/89 processed 5,486 batch-loss 10.7428 epoch-elapsed 0h00m38s total-elapsed 0h23m37s\n",
            "epoch 6 batch 18/89 processed 5,496 batch-loss 8.2550 epoch-elapsed 0h00m40s total-elapsed 0h23m39s\n",
            "epoch 6 batch 19/89 processed 5,506 batch-loss 8.2929 epoch-elapsed 0h00m42s total-elapsed 0h23m41s\n",
            "epoch 6 batch 20/89 processed 5,516 batch-loss 14.5643 epoch-elapsed 0h00m46s total-elapsed 0h23m45s\n",
            "epoch 6 batch 21/89 processed 5,526 batch-loss 8.8997 epoch-elapsed 0h00m48s total-elapsed 0h23m47s\n",
            "epoch 6 batch 22/89 processed 5,536 batch-loss 12.8709 epoch-elapsed 0h00m52s total-elapsed 0h23m51s\n",
            "epoch 6 batch 23/89 processed 5,546 batch-loss 21.8662 epoch-elapsed 0h00m56s total-elapsed 0h23m55s\n",
            "epoch 6 batch 24/89 processed 5,556 batch-loss 11.6418 epoch-elapsed 0h00m59s total-elapsed 0h23m58s\n",
            "epoch 6 batch 25/89 processed 5,566 batch-loss 10.2425 epoch-elapsed 0h01m01s total-elapsed 0h24m00s\n",
            "epoch 6 batch 26/89 processed 5,576 batch-loss 9.6554 epoch-elapsed 0h01m04s total-elapsed 0h24m03s\n",
            "epoch 6 batch 27/89 processed 5,586 batch-loss 8.1613 epoch-elapsed 0h01m06s total-elapsed 0h24m05s\n",
            "epoch 6 batch 28/89 processed 5,596 batch-loss 12.0672 epoch-elapsed 0h01m09s total-elapsed 0h24m08s\n",
            "epoch 6 batch 29/89 processed 5,606 batch-loss 10.7200 epoch-elapsed 0h01m12s total-elapsed 0h24m11s\n",
            "epoch 6 batch 30/89 processed 5,616 batch-loss 7.7704 epoch-elapsed 0h01m14s total-elapsed 0h24m13s\n",
            "epoch 6 batch 31/89 processed 5,626 batch-loss 7.7511 epoch-elapsed 0h01m17s total-elapsed 0h24m16s\n",
            "epoch 6 batch 32/89 processed 5,636 batch-loss 11.8396 epoch-elapsed 0h01m20s total-elapsed 0h24m20s\n",
            "epoch 6 batch 33/89 processed 5,646 batch-loss 16.2927 epoch-elapsed 0h01m26s total-elapsed 0h24m25s\n",
            "epoch 6 batch 34/89 processed 5,656 batch-loss 11.6533 epoch-elapsed 0h01m29s total-elapsed 0h24m28s\n",
            "epoch 6 batch 35/89 processed 5,666 batch-loss 9.5402 epoch-elapsed 0h01m32s total-elapsed 0h24m31s\n",
            "epoch 6 batch 36/89 processed 5,676 batch-loss 9.9220 epoch-elapsed 0h01m34s total-elapsed 0h24m33s\n",
            "epoch 6 batch 37/89 processed 5,686 batch-loss 11.8288 epoch-elapsed 0h01m36s total-elapsed 0h24m36s\n",
            "epoch 6 batch 38/89 processed 5,696 batch-loss 5.0510 epoch-elapsed 0h01m38s total-elapsed 0h24m38s\n",
            "epoch 6 batch 39/89 processed 5,706 batch-loss 6.5054 epoch-elapsed 0h01m40s total-elapsed 0h24m40s\n",
            "epoch 6 batch 40/89 processed 5,716 batch-loss 11.8688 epoch-elapsed 0h01m44s total-elapsed 0h24m43s\n",
            "epoch 6 batch 41/89 processed 5,726 batch-loss 7.3646 epoch-elapsed 0h01m46s total-elapsed 0h24m45s\n",
            "epoch 6 batch 42/89 processed 5,736 batch-loss 10.3791 epoch-elapsed 0h01m48s total-elapsed 0h24m47s\n",
            "epoch 6 batch 43/89 processed 5,746 batch-loss 13.8332 epoch-elapsed 0h01m50s total-elapsed 0h24m50s\n",
            "epoch 6 batch 44/89 processed 5,756 batch-loss 9.5036 epoch-elapsed 0h01m53s total-elapsed 0h24m52s\n",
            "epoch 6 batch 45/89 processed 5,766 batch-loss 17.9509 epoch-elapsed 0h01m58s total-elapsed 0h24m57s\n",
            "epoch 6 batch 46/89 processed 5,776 batch-loss 6.9730 epoch-elapsed 0h02m00s total-elapsed 0h24m59s\n",
            "epoch 6 batch 47/89 processed 5,786 batch-loss 8.3829 epoch-elapsed 0h02m02s total-elapsed 0h25m01s\n",
            "epoch 6 batch 48/89 processed 5,796 batch-loss 15.6766 epoch-elapsed 0h02m05s total-elapsed 0h25m04s\n",
            "epoch 6 batch 49/89 processed 5,806 batch-loss 16.2868 epoch-elapsed 0h02m09s total-elapsed 0h25m08s\n",
            "epoch 6 batch 50/89 processed 5,816 batch-loss 8.1269 epoch-elapsed 0h02m11s total-elapsed 0h25m10s\n",
            "epoch 6 batch 51/89 processed 5,826 batch-loss 10.9485 epoch-elapsed 0h02m13s total-elapsed 0h25m12s\n",
            "epoch 6 batch 52/89 processed 5,836 batch-loss 14.1054 epoch-elapsed 0h02m17s total-elapsed 0h25m16s\n",
            "epoch 6 batch 53/89 processed 5,846 batch-loss 11.0400 epoch-elapsed 0h02m19s total-elapsed 0h25m18s\n",
            "epoch 6 batch 54/89 processed 5,856 batch-loss 10.4601 epoch-elapsed 0h02m22s total-elapsed 0h25m21s\n",
            "epoch 6 batch 55/89 processed 5,866 batch-loss 13.2917 epoch-elapsed 0h02m24s total-elapsed 0h25m23s\n",
            "epoch 6 batch 56/89 processed 5,876 batch-loss 6.4180 epoch-elapsed 0h02m26s total-elapsed 0h25m26s\n",
            "epoch 6 batch 57/89 processed 5,886 batch-loss 8.0067 epoch-elapsed 0h02m29s total-elapsed 0h25m28s\n",
            "epoch 6 batch 58/89 processed 5,896 batch-loss 12.3756 epoch-elapsed 0h02m31s total-elapsed 0h25m30s\n",
            "epoch 6 batch 59/89 processed 5,906 batch-loss 8.9844 epoch-elapsed 0h02m34s total-elapsed 0h25m33s\n",
            "epoch 6 batch 60/89 processed 5,916 batch-loss 8.6721 epoch-elapsed 0h02m36s total-elapsed 0h25m35s\n",
            "epoch 6 batch 61/89 processed 5,926 batch-loss 13.1867 epoch-elapsed 0h02m39s total-elapsed 0h25m38s\n",
            "epoch 6 batch 62/89 processed 5,936 batch-loss 11.6485 epoch-elapsed 0h02m41s total-elapsed 0h25m40s\n",
            "epoch 6 batch 63/89 processed 5,946 batch-loss 11.2488 epoch-elapsed 0h02m43s total-elapsed 0h25m43s\n",
            "epoch 6 batch 64/89 processed 5,956 batch-loss 10.5308 epoch-elapsed 0h02m45s total-elapsed 0h25m45s\n",
            "epoch 6 batch 65/89 processed 5,966 batch-loss 5.7987 epoch-elapsed 0h02m47s total-elapsed 0h25m46s\n",
            "epoch 6 batch 66/89 processed 5,976 batch-loss 9.1472 epoch-elapsed 0h02m50s total-elapsed 0h25m49s\n",
            "epoch 6 batch 67/89 processed 5,986 batch-loss 5.1733 epoch-elapsed 0h02m52s total-elapsed 0h25m51s\n",
            "epoch 6 batch 68/89 processed 5,996 batch-loss 9.4346 epoch-elapsed 0h02m54s total-elapsed 0h25m53s\n",
            "epoch 6 batch 69/89 processed 6,006 batch-loss 7.3826 epoch-elapsed 0h02m56s total-elapsed 0h25m55s\n",
            "epoch 6 batch 70/89 processed 6,016 batch-loss 15.5463 epoch-elapsed 0h03m00s total-elapsed 0h25m59s\n",
            "epoch 6 batch 71/89 processed 6,026 batch-loss 9.8220 epoch-elapsed 0h03m02s total-elapsed 0h26m02s\n",
            "epoch 6 batch 72/89 processed 6,036 batch-loss 6.1021 epoch-elapsed 0h03m04s total-elapsed 0h26m03s\n",
            "epoch 6 batch 73/89 processed 6,046 batch-loss 8.5995 epoch-elapsed 0h03m07s total-elapsed 0h26m06s\n",
            "epoch 6 batch 74/89 processed 6,056 batch-loss 10.3343 epoch-elapsed 0h03m10s total-elapsed 0h26m09s\n",
            "epoch 6 batch 75/89 processed 6,066 batch-loss 12.2685 epoch-elapsed 0h03m12s total-elapsed 0h26m11s\n",
            "epoch 6 batch 76/89 processed 6,076 batch-loss 6.4919 epoch-elapsed 0h03m15s total-elapsed 0h26m14s\n",
            "epoch 6 batch 77/89 processed 6,086 batch-loss 13.3583 epoch-elapsed 0h03m18s total-elapsed 0h26m17s\n",
            "epoch 6 batch 78/89 processed 6,096 batch-loss 7.5569 epoch-elapsed 0h03m20s total-elapsed 0h26m19s\n",
            "epoch 6 batch 79/89 processed 6,106 batch-loss 12.2227 epoch-elapsed 0h03m23s total-elapsed 0h26m22s\n",
            "epoch 6 batch 80/89 processed 6,116 batch-loss 8.0643 epoch-elapsed 0h03m25s total-elapsed 0h26m24s\n",
            "epoch 6 batch 81/89 processed 6,126 batch-loss 8.0358 epoch-elapsed 0h03m28s total-elapsed 0h26m27s\n",
            "epoch 6 batch 82/89 processed 6,136 batch-loss 10.8915 epoch-elapsed 0h03m30s total-elapsed 0h26m30s\n",
            "epoch 6 batch 83/89 processed 6,146 batch-loss 18.7651 epoch-elapsed 0h03m34s total-elapsed 0h26m33s\n",
            "epoch 6 batch 84/89 processed 6,156 batch-loss 12.4922 epoch-elapsed 0h03m37s total-elapsed 0h26m36s\n",
            "epoch 6 batch 85/89 processed 6,166 batch-loss 10.7700 epoch-elapsed 0h03m40s total-elapsed 0h26m39s\n",
            "epoch 6 batch 86/89 processed 6,176 batch-loss 8.4569 epoch-elapsed 0h03m42s total-elapsed 0h26m42s\n",
            "epoch 6 batch 87/89 processed 6,186 batch-loss 11.2101 epoch-elapsed 0h03m45s total-elapsed 0h26m44s\n",
            "epoch 6 batch 88/89 processed 6,196 batch-loss 5.3050 epoch-elapsed 0h03m47s total-elapsed 0h26m46s\n",
            "epoch 6 batch 89/89 processed 6,202 batch-loss 11.7292 epoch-elapsed 0h03m48s total-elapsed 0h26m47s\n",
            "epoch 7 batch 1/89 processed 6,212 batch-loss 12.7658 epoch-elapsed 0h00m02s total-elapsed 0h26m50s\n",
            "epoch 7 batch 2/89 processed 6,222 batch-loss 17.2468 epoch-elapsed 0h00m06s total-elapsed 0h26m54s\n",
            "epoch 7 batch 3/89 processed 6,232 batch-loss 5.8793 epoch-elapsed 0h00m08s total-elapsed 0h26m56s\n",
            "epoch 7 batch 4/89 processed 6,242 batch-loss 8.0540 epoch-elapsed 0h00m10s total-elapsed 0h26m58s\n",
            "epoch 7 batch 5/89 processed 6,252 batch-loss 7.7877 epoch-elapsed 0h00m13s total-elapsed 0h27m01s\n",
            "epoch 7 batch 6/89 processed 6,262 batch-loss 12.8598 epoch-elapsed 0h00m16s total-elapsed 0h27m04s\n",
            "epoch 7 batch 7/89 processed 6,272 batch-loss 5.2588 epoch-elapsed 0h00m18s total-elapsed 0h27m06s\n",
            "epoch 7 batch 8/89 processed 6,282 batch-loss 8.0914 epoch-elapsed 0h00m20s total-elapsed 0h27m08s\n",
            "epoch 7 batch 9/89 processed 6,292 batch-loss 9.4485 epoch-elapsed 0h00m23s total-elapsed 0h27m11s\n",
            "epoch 7 batch 10/89 processed 6,302 batch-loss 7.1676 epoch-elapsed 0h00m25s total-elapsed 0h27m13s\n",
            "epoch 7 batch 11/89 processed 6,312 batch-loss 7.9702 epoch-elapsed 0h00m27s total-elapsed 0h27m15s\n",
            "epoch 7 batch 12/89 processed 6,322 batch-loss 7.6989 epoch-elapsed 0h00m30s total-elapsed 0h27m18s\n",
            "epoch 7 batch 13/89 processed 6,332 batch-loss 5.1520 epoch-elapsed 0h00m31s total-elapsed 0h27m19s\n",
            "epoch 7 batch 14/89 processed 6,342 batch-loss 10.0308 epoch-elapsed 0h00m35s total-elapsed 0h27m22s\n",
            "epoch 7 batch 15/89 processed 6,352 batch-loss 10.2741 epoch-elapsed 0h00m37s total-elapsed 0h27m25s\n",
            "epoch 7 batch 16/89 processed 6,362 batch-loss 8.1933 epoch-elapsed 0h00m39s total-elapsed 0h27m27s\n",
            "epoch 7 batch 17/89 processed 6,372 batch-loss 12.2562 epoch-elapsed 0h00m42s total-elapsed 0h27m30s\n",
            "epoch 7 batch 18/89 processed 6,382 batch-loss 8.5382 epoch-elapsed 0h00m45s total-elapsed 0h27m33s\n",
            "epoch 7 batch 19/89 processed 6,392 batch-loss 9.7210 epoch-elapsed 0h00m47s total-elapsed 0h27m35s\n",
            "epoch 7 batch 20/89 processed 6,402 batch-loss 13.3216 epoch-elapsed 0h00m51s total-elapsed 0h27m39s\n",
            "epoch 7 batch 21/89 processed 6,412 batch-loss 7.2065 epoch-elapsed 0h00m53s total-elapsed 0h27m41s\n",
            "epoch 7 batch 22/89 processed 6,422 batch-loss 3.9155 epoch-elapsed 0h00m54s total-elapsed 0h27m42s\n",
            "epoch 7 batch 23/89 processed 6,432 batch-loss 7.3148 epoch-elapsed 0h00m56s total-elapsed 0h27m44s\n",
            "epoch 7 batch 24/89 processed 6,442 batch-loss 8.0713 epoch-elapsed 0h00m59s total-elapsed 0h27m47s\n",
            "epoch 7 batch 25/89 processed 6,452 batch-loss 10.2411 epoch-elapsed 0h01m01s total-elapsed 0h27m49s\n",
            "epoch 7 batch 26/89 processed 6,462 batch-loss 14.1130 epoch-elapsed 0h01m05s total-elapsed 0h27m53s\n",
            "epoch 7 batch 27/89 processed 6,472 batch-loss 11.1648 epoch-elapsed 0h01m08s total-elapsed 0h27m55s\n",
            "epoch 7 batch 28/89 processed 6,482 batch-loss 10.2504 epoch-elapsed 0h01m10s total-elapsed 0h27m58s\n",
            "epoch 7 batch 29/89 processed 6,492 batch-loss 8.7823 epoch-elapsed 0h01m12s total-elapsed 0h28m00s\n",
            "epoch 7 batch 30/89 processed 6,502 batch-loss 10.4020 epoch-elapsed 0h01m15s total-elapsed 0h28m03s\n",
            "epoch 7 batch 31/89 processed 6,512 batch-loss 7.2124 epoch-elapsed 0h01m17s total-elapsed 0h28m05s\n",
            "epoch 7 batch 32/89 processed 6,522 batch-loss 12.4604 epoch-elapsed 0h01m20s total-elapsed 0h28m08s\n",
            "epoch 7 batch 33/89 processed 6,532 batch-loss 7.5843 epoch-elapsed 0h01m22s total-elapsed 0h28m10s\n",
            "epoch 7 batch 34/89 processed 6,542 batch-loss 11.8915 epoch-elapsed 0h01m25s total-elapsed 0h28m13s\n",
            "epoch 7 batch 35/89 processed 6,552 batch-loss 8.0252 epoch-elapsed 0h01m28s total-elapsed 0h28m16s\n",
            "epoch 7 batch 36/89 processed 6,562 batch-loss 12.3955 epoch-elapsed 0h01m31s total-elapsed 0h28m19s\n",
            "epoch 7 batch 37/89 processed 6,572 batch-loss 10.9080 epoch-elapsed 0h01m34s total-elapsed 0h28m22s\n",
            "epoch 7 batch 38/89 processed 6,582 batch-loss 10.0554 epoch-elapsed 0h01m37s total-elapsed 0h28m25s\n",
            "epoch 7 batch 39/89 processed 6,592 batch-loss 12.2466 epoch-elapsed 0h01m40s total-elapsed 0h28m28s\n",
            "epoch 7 batch 40/89 processed 6,602 batch-loss 7.1981 epoch-elapsed 0h01m43s total-elapsed 0h28m31s\n",
            "epoch 7 batch 41/89 processed 6,612 batch-loss 15.5294 epoch-elapsed 0h01m47s total-elapsed 0h28m35s\n",
            "epoch 7 batch 42/89 processed 6,622 batch-loss 8.3412 epoch-elapsed 0h01m49s total-elapsed 0h28m37s\n",
            "epoch 7 batch 43/89 processed 6,632 batch-loss 8.0994 epoch-elapsed 0h01m51s total-elapsed 0h28m39s\n",
            "epoch 7 batch 44/89 processed 6,642 batch-loss 5.9235 epoch-elapsed 0h01m53s total-elapsed 0h28m41s\n",
            "epoch 7 batch 45/89 processed 6,652 batch-loss 9.5110 epoch-elapsed 0h01m56s total-elapsed 0h28m44s\n",
            "epoch 7 batch 46/89 processed 6,662 batch-loss 13.6206 epoch-elapsed 0h01m59s total-elapsed 0h28m46s\n",
            "epoch 7 batch 47/89 processed 6,672 batch-loss 5.8689 epoch-elapsed 0h02m01s total-elapsed 0h28m49s\n",
            "epoch 7 batch 48/89 processed 6,682 batch-loss 6.8258 epoch-elapsed 0h02m04s total-elapsed 0h28m52s\n",
            "epoch 7 batch 49/89 processed 6,692 batch-loss 12.6277 epoch-elapsed 0h02m08s total-elapsed 0h28m56s\n",
            "epoch 7 batch 50/89 processed 6,702 batch-loss 5.1018 epoch-elapsed 0h02m10s total-elapsed 0h28m58s\n",
            "epoch 7 batch 51/89 processed 6,712 batch-loss 9.5874 epoch-elapsed 0h02m13s total-elapsed 0h29m01s\n",
            "epoch 7 batch 52/89 processed 6,722 batch-loss 8.0288 epoch-elapsed 0h02m15s total-elapsed 0h29m03s\n",
            "epoch 7 batch 53/89 processed 6,732 batch-loss 5.4570 epoch-elapsed 0h02m17s total-elapsed 0h29m05s\n",
            "epoch 7 batch 54/89 processed 6,742 batch-loss 10.0206 epoch-elapsed 0h02m19s total-elapsed 0h29m07s\n",
            "epoch 7 batch 55/89 processed 6,752 batch-loss 12.2995 epoch-elapsed 0h02m23s total-elapsed 0h29m11s\n",
            "epoch 7 batch 56/89 processed 6,762 batch-loss 8.3717 epoch-elapsed 0h02m26s total-elapsed 0h29m14s\n",
            "epoch 7 batch 57/89 processed 6,772 batch-loss 10.0185 epoch-elapsed 0h02m29s total-elapsed 0h29m17s\n",
            "epoch 7 batch 58/89 processed 6,782 batch-loss 11.6311 epoch-elapsed 0h02m31s total-elapsed 0h29m19s\n",
            "epoch 7 batch 59/89 processed 6,792 batch-loss 11.2022 epoch-elapsed 0h02m34s total-elapsed 0h29m22s\n",
            "epoch 7 batch 60/89 processed 6,802 batch-loss 9.9844 epoch-elapsed 0h02m38s total-elapsed 0h29m25s\n",
            "epoch 7 batch 61/89 processed 6,812 batch-loss 13.0605 epoch-elapsed 0h02m41s total-elapsed 0h29m29s\n",
            "epoch 7 batch 62/89 processed 6,822 batch-loss 6.4461 epoch-elapsed 0h02m43s total-elapsed 0h29m31s\n",
            "epoch 7 batch 63/89 processed 6,832 batch-loss 11.3813 epoch-elapsed 0h02m45s total-elapsed 0h29m33s\n",
            "epoch 7 batch 64/89 processed 6,842 batch-loss 4.9242 epoch-elapsed 0h02m47s total-elapsed 0h29m35s\n",
            "epoch 7 batch 65/89 processed 6,852 batch-loss 7.4544 epoch-elapsed 0h02m49s total-elapsed 0h29m37s\n",
            "epoch 7 batch 66/89 processed 6,862 batch-loss 10.2388 epoch-elapsed 0h02m52s total-elapsed 0h29m40s\n",
            "epoch 7 batch 67/89 processed 6,872 batch-loss 10.9757 epoch-elapsed 0h02m55s total-elapsed 0h29m43s\n",
            "epoch 7 batch 68/89 processed 6,882 batch-loss 7.1864 epoch-elapsed 0h02m58s total-elapsed 0h29m45s\n",
            "epoch 7 batch 69/89 processed 6,892 batch-loss 10.8985 epoch-elapsed 0h03m00s total-elapsed 0h29m48s\n",
            "epoch 7 batch 70/89 processed 6,902 batch-loss 6.5594 epoch-elapsed 0h03m03s total-elapsed 0h29m50s\n",
            "epoch 7 batch 71/89 processed 6,912 batch-loss 5.1217 epoch-elapsed 0h03m04s total-elapsed 0h29m52s\n",
            "epoch 7 batch 72/89 processed 6,922 batch-loss 8.9231 epoch-elapsed 0h03m07s total-elapsed 0h29m55s\n",
            "epoch 7 batch 73/89 processed 6,932 batch-loss 6.4179 epoch-elapsed 0h03m09s total-elapsed 0h29m57s\n",
            "epoch 7 batch 74/89 processed 6,942 batch-loss 9.9029 epoch-elapsed 0h03m12s total-elapsed 0h30m00s\n",
            "epoch 7 batch 75/89 processed 6,952 batch-loss 10.0317 epoch-elapsed 0h03m15s total-elapsed 0h30m03s\n",
            "epoch 7 batch 76/89 processed 6,962 batch-loss 5.9365 epoch-elapsed 0h03m17s total-elapsed 0h30m05s\n",
            "epoch 7 batch 77/89 processed 6,972 batch-loss 7.0460 epoch-elapsed 0h03m19s total-elapsed 0h30m07s\n",
            "epoch 7 batch 78/89 processed 6,982 batch-loss 11.0212 epoch-elapsed 0h03m22s total-elapsed 0h30m10s\n",
            "epoch 7 batch 79/89 processed 6,992 batch-loss 11.5270 epoch-elapsed 0h03m25s total-elapsed 0h30m12s\n",
            "epoch 7 batch 80/89 processed 7,002 batch-loss 6.9685 epoch-elapsed 0h03m27s total-elapsed 0h30m15s\n",
            "epoch 7 batch 81/89 processed 7,012 batch-loss 7.9921 epoch-elapsed 0h03m29s total-elapsed 0h30m17s\n",
            "epoch 7 batch 82/89 processed 7,022 batch-loss 10.7587 epoch-elapsed 0h03m31s total-elapsed 0h30m19s\n",
            "epoch 7 batch 83/89 processed 7,032 batch-loss 6.9554 epoch-elapsed 0h03m34s total-elapsed 0h30m22s\n",
            "epoch 7 batch 84/89 processed 7,042 batch-loss 5.8657 epoch-elapsed 0h03m36s total-elapsed 0h30m24s\n",
            "epoch 7 batch 85/89 processed 7,052 batch-loss 5.9311 epoch-elapsed 0h03m38s total-elapsed 0h30m26s\n",
            "epoch 7 batch 86/89 processed 7,062 batch-loss 9.4424 epoch-elapsed 0h03m41s total-elapsed 0h30m29s\n",
            "epoch 7 batch 87/89 processed 7,072 batch-loss 5.6125 epoch-elapsed 0h03m43s total-elapsed 0h30m31s\n",
            "epoch 7 batch 88/89 processed 7,082 batch-loss 8.0749 epoch-elapsed 0h03m45s total-elapsed 0h30m33s\n",
            "epoch 7 batch 89/89 processed 7,088 batch-loss 7.5422 epoch-elapsed 0h03m46s total-elapsed 0h30m34s\n",
            "epoch 8 batch 1/89 processed 7,098 batch-loss 9.8689 epoch-elapsed 0h00m02s total-elapsed 0h30m36s\n",
            "epoch 8 batch 2/89 processed 7,108 batch-loss 8.5226 epoch-elapsed 0h00m04s total-elapsed 0h30m39s\n",
            "epoch 8 batch 3/89 processed 7,118 batch-loss 7.5126 epoch-elapsed 0h00m06s total-elapsed 0h30m41s\n",
            "epoch 8 batch 4/89 processed 7,128 batch-loss 11.3063 epoch-elapsed 0h00m10s total-elapsed 0h30m44s\n",
            "epoch 8 batch 5/89 processed 7,138 batch-loss 10.0989 epoch-elapsed 0h00m14s total-elapsed 0h30m48s\n",
            "epoch 8 batch 6/89 processed 7,148 batch-loss 10.4134 epoch-elapsed 0h00m16s total-elapsed 0h30m51s\n",
            "epoch 8 batch 7/89 processed 7,158 batch-loss 7.4517 epoch-elapsed 0h00m18s total-elapsed 0h30m53s\n",
            "epoch 8 batch 8/89 processed 7,168 batch-loss 7.7324 epoch-elapsed 0h00m21s total-elapsed 0h30m55s\n",
            "epoch 8 batch 9/89 processed 7,178 batch-loss 9.3232 epoch-elapsed 0h00m23s total-elapsed 0h30m58s\n",
            "epoch 8 batch 10/89 processed 7,188 batch-loss 4.4897 epoch-elapsed 0h00m25s total-elapsed 0h30m59s\n",
            "epoch 8 batch 11/89 processed 7,198 batch-loss 10.8804 epoch-elapsed 0h00m27s total-elapsed 0h31m02s\n",
            "epoch 8 batch 12/89 processed 7,208 batch-loss 15.1388 epoch-elapsed 0h00m31s total-elapsed 0h31m05s\n",
            "epoch 8 batch 13/89 processed 7,218 batch-loss 8.3745 epoch-elapsed 0h00m33s total-elapsed 0h31m08s\n",
            "epoch 8 batch 14/89 processed 7,228 batch-loss 11.8980 epoch-elapsed 0h00m36s total-elapsed 0h31m11s\n",
            "epoch 8 batch 15/89 processed 7,238 batch-loss 6.1664 epoch-elapsed 0h00m39s total-elapsed 0h31m13s\n",
            "epoch 8 batch 16/89 processed 7,248 batch-loss 6.7336 epoch-elapsed 0h00m41s total-elapsed 0h31m15s\n",
            "epoch 8 batch 17/89 processed 7,258 batch-loss 4.9802 epoch-elapsed 0h00m43s total-elapsed 0h31m17s\n",
            "epoch 8 batch 18/89 processed 7,268 batch-loss 6.7017 epoch-elapsed 0h00m45s total-elapsed 0h31m20s\n",
            "epoch 8 batch 19/89 processed 7,278 batch-loss 7.6879 epoch-elapsed 0h00m48s total-elapsed 0h31m23s\n",
            "epoch 8 batch 20/89 processed 7,288 batch-loss 11.3536 epoch-elapsed 0h00m51s total-elapsed 0h31m26s\n",
            "epoch 8 batch 21/89 processed 7,298 batch-loss 6.4643 epoch-elapsed 0h00m54s total-elapsed 0h31m28s\n",
            "epoch 8 batch 22/89 processed 7,308 batch-loss 10.3161 epoch-elapsed 0h00m56s total-elapsed 0h31m30s\n",
            "epoch 8 batch 23/89 processed 7,318 batch-loss 8.6492 epoch-elapsed 0h00m59s total-elapsed 0h31m33s\n",
            "epoch 8 batch 24/89 processed 7,328 batch-loss 4.0470 epoch-elapsed 0h01m00s total-elapsed 0h31m35s\n",
            "epoch 8 batch 25/89 processed 7,338 batch-loss 5.3317 epoch-elapsed 0h01m02s total-elapsed 0h31m37s\n",
            "epoch 8 batch 26/89 processed 7,348 batch-loss 6.1412 epoch-elapsed 0h01m05s total-elapsed 0h31m39s\n",
            "epoch 8 batch 27/89 processed 7,358 batch-loss 5.4621 epoch-elapsed 0h01m06s total-elapsed 0h31m41s\n",
            "epoch 8 batch 28/89 processed 7,368 batch-loss 6.1369 epoch-elapsed 0h01m09s total-elapsed 0h31m43s\n",
            "epoch 8 batch 29/89 processed 7,378 batch-loss 6.9832 epoch-elapsed 0h01m11s total-elapsed 0h31m46s\n",
            "epoch 8 batch 30/89 processed 7,388 batch-loss 7.5790 epoch-elapsed 0h01m13s total-elapsed 0h31m48s\n",
            "epoch 8 batch 31/89 processed 7,398 batch-loss 7.2286 epoch-elapsed 0h01m16s total-elapsed 0h31m50s\n",
            "epoch 8 batch 32/89 processed 7,408 batch-loss 10.3433 epoch-elapsed 0h01m18s total-elapsed 0h31m53s\n",
            "epoch 8 batch 33/89 processed 7,418 batch-loss 7.6420 epoch-elapsed 0h01m20s total-elapsed 0h31m55s\n",
            "epoch 8 batch 34/89 processed 7,428 batch-loss 9.9689 epoch-elapsed 0h01m23s total-elapsed 0h31m58s\n",
            "epoch 8 batch 35/89 processed 7,438 batch-loss 6.2365 epoch-elapsed 0h01m25s total-elapsed 0h32m00s\n",
            "epoch 8 batch 36/89 processed 7,448 batch-loss 5.4057 epoch-elapsed 0h01m27s total-elapsed 0h32m02s\n",
            "epoch 8 batch 37/89 processed 7,458 batch-loss 6.7580 epoch-elapsed 0h01m30s total-elapsed 0h32m04s\n",
            "epoch 8 batch 38/89 processed 7,468 batch-loss 9.2774 epoch-elapsed 0h01m33s total-elapsed 0h32m07s\n",
            "epoch 8 batch 39/89 processed 7,478 batch-loss 10.9041 epoch-elapsed 0h01m36s total-elapsed 0h32m10s\n",
            "epoch 8 batch 40/89 processed 7,488 batch-loss 11.3192 epoch-elapsed 0h01m39s total-elapsed 0h32m14s\n",
            "epoch 8 batch 41/89 processed 7,498 batch-loss 7.7915 epoch-elapsed 0h01m42s total-elapsed 0h32m17s\n",
            "epoch 8 batch 42/89 processed 7,508 batch-loss 6.0136 epoch-elapsed 0h01m44s total-elapsed 0h32m18s\n",
            "epoch 8 batch 43/89 processed 7,518 batch-loss 2.4272 epoch-elapsed 0h01m45s total-elapsed 0h32m19s\n",
            "epoch 8 batch 44/89 processed 7,528 batch-loss 9.0520 epoch-elapsed 0h01m48s total-elapsed 0h32m22s\n",
            "epoch 8 batch 45/89 processed 7,538 batch-loss 2.7202 epoch-elapsed 0h01m50s total-elapsed 0h32m24s\n",
            "epoch 8 batch 46/89 processed 7,548 batch-loss 6.0711 epoch-elapsed 0h01m51s total-elapsed 0h32m26s\n",
            "epoch 8 batch 47/89 processed 7,558 batch-loss 9.9046 epoch-elapsed 0h01m54s total-elapsed 0h32m29s\n",
            "epoch 8 batch 48/89 processed 7,568 batch-loss 7.0193 epoch-elapsed 0h01m56s total-elapsed 0h32m31s\n",
            "epoch 8 batch 49/89 processed 7,578 batch-loss 8.0579 epoch-elapsed 0h01m59s total-elapsed 0h32m34s\n",
            "epoch 8 batch 50/89 processed 7,588 batch-loss 8.5772 epoch-elapsed 0h02m02s total-elapsed 0h32m36s\n",
            "epoch 8 batch 51/89 processed 7,598 batch-loss 6.7308 epoch-elapsed 0h02m04s total-elapsed 0h32m39s\n",
            "epoch 8 batch 52/89 processed 7,608 batch-loss 9.1444 epoch-elapsed 0h02m07s total-elapsed 0h32m42s\n",
            "epoch 8 batch 53/89 processed 7,618 batch-loss 4.3156 epoch-elapsed 0h02m09s total-elapsed 0h32m43s\n",
            "epoch 8 batch 54/89 processed 7,628 batch-loss 9.0062 epoch-elapsed 0h02m11s total-elapsed 0h32m46s\n",
            "epoch 8 batch 55/89 processed 7,638 batch-loss 7.9632 epoch-elapsed 0h02m14s total-elapsed 0h32m48s\n",
            "epoch 8 batch 56/89 processed 7,648 batch-loss 10.8086 epoch-elapsed 0h02m17s total-elapsed 0h32m51s\n",
            "epoch 8 batch 57/89 processed 7,658 batch-loss 4.9249 epoch-elapsed 0h02m19s total-elapsed 0h32m54s\n",
            "epoch 8 batch 58/89 processed 7,668 batch-loss 13.6686 epoch-elapsed 0h02m23s total-elapsed 0h32m58s\n",
            "epoch 8 batch 59/89 processed 7,678 batch-loss 14.7502 epoch-elapsed 0h02m27s total-elapsed 0h33m02s\n",
            "epoch 8 batch 60/89 processed 7,688 batch-loss 6.6825 epoch-elapsed 0h02m29s total-elapsed 0h33m04s\n",
            "epoch 8 batch 61/89 processed 7,698 batch-loss 9.0818 epoch-elapsed 0h02m32s total-elapsed 0h33m07s\n",
            "epoch 8 batch 62/89 processed 7,708 batch-loss 6.5876 epoch-elapsed 0h02m34s total-elapsed 0h33m09s\n",
            "epoch 8 batch 63/89 processed 7,718 batch-loss 7.0282 epoch-elapsed 0h02m37s total-elapsed 0h33m11s\n",
            "epoch 8 batch 64/89 processed 7,728 batch-loss 11.1955 epoch-elapsed 0h02m44s total-elapsed 0h33m18s\n",
            "epoch 8 batch 65/89 processed 7,738 batch-loss 7.1490 epoch-elapsed 0h02m46s total-elapsed 0h33m20s\n",
            "epoch 8 batch 66/89 processed 7,748 batch-loss 7.1574 epoch-elapsed 0h02m49s total-elapsed 0h33m23s\n",
            "epoch 8 batch 67/89 processed 7,758 batch-loss 8.9106 epoch-elapsed 0h02m51s total-elapsed 0h33m25s\n",
            "epoch 8 batch 68/89 processed 7,768 batch-loss 12.7453 epoch-elapsed 0h02m54s total-elapsed 0h33m28s\n",
            "epoch 8 batch 69/89 processed 7,778 batch-loss 11.5027 epoch-elapsed 0h02m58s total-elapsed 0h33m32s\n",
            "epoch 8 batch 70/89 processed 7,788 batch-loss 5.1215 epoch-elapsed 0h03m00s total-elapsed 0h33m34s\n",
            "epoch 8 batch 71/89 processed 7,798 batch-loss 3.9952 epoch-elapsed 0h03m02s total-elapsed 0h33m36s\n",
            "epoch 8 batch 72/89 processed 7,808 batch-loss 10.8098 epoch-elapsed 0h03m05s total-elapsed 0h33m40s\n",
            "epoch 8 batch 73/89 processed 7,818 batch-loss 4.8909 epoch-elapsed 0h03m07s total-elapsed 0h33m42s\n",
            "epoch 8 batch 74/89 processed 7,828 batch-loss 7.9254 epoch-elapsed 0h03m10s total-elapsed 0h33m44s\n",
            "epoch 8 batch 75/89 processed 7,838 batch-loss 5.8997 epoch-elapsed 0h03m12s total-elapsed 0h33m46s\n",
            "epoch 8 batch 76/89 processed 7,848 batch-loss 7.8298 epoch-elapsed 0h03m14s total-elapsed 0h33m48s\n",
            "epoch 8 batch 77/89 processed 7,858 batch-loss 5.9393 epoch-elapsed 0h03m16s total-elapsed 0h33m50s\n",
            "epoch 8 batch 78/89 processed 7,868 batch-loss 8.9721 epoch-elapsed 0h03m18s total-elapsed 0h33m53s\n",
            "epoch 8 batch 79/89 processed 7,878 batch-loss 5.5007 epoch-elapsed 0h03m20s total-elapsed 0h33m55s\n",
            "epoch 8 batch 80/89 processed 7,888 batch-loss 5.6261 epoch-elapsed 0h03m23s total-elapsed 0h33m57s\n",
            "epoch 8 batch 81/89 processed 7,898 batch-loss 9.7067 epoch-elapsed 0h03m26s total-elapsed 0h34m00s\n",
            "epoch 8 batch 82/89 processed 7,908 batch-loss 5.3660 epoch-elapsed 0h03m28s total-elapsed 0h34m02s\n",
            "epoch 8 batch 83/89 processed 7,918 batch-loss 9.6956 epoch-elapsed 0h03m30s total-elapsed 0h34m05s\n",
            "epoch 8 batch 84/89 processed 7,928 batch-loss 5.8641 epoch-elapsed 0h03m33s total-elapsed 0h34m07s\n",
            "epoch 8 batch 85/89 processed 7,938 batch-loss 17.9903 epoch-elapsed 0h03m36s total-elapsed 0h34m10s\n",
            "epoch 8 batch 86/89 processed 7,948 batch-loss 7.1940 epoch-elapsed 0h03m39s total-elapsed 0h34m13s\n",
            "epoch 8 batch 87/89 processed 7,958 batch-loss 6.9427 epoch-elapsed 0h03m42s total-elapsed 0h34m16s\n",
            "epoch 8 batch 88/89 processed 7,968 batch-loss 10.3584 epoch-elapsed 0h03m44s total-elapsed 0h34m18s\n",
            "epoch 8 batch 89/89 processed 7,974 batch-loss 14.1096 epoch-elapsed 0h03m46s total-elapsed 0h34m20s\n",
            "epoch 9 batch 1/89 processed 7,984 batch-loss 7.4110 epoch-elapsed 0h00m03s total-elapsed 0h34m23s\n",
            "epoch 9 batch 2/89 processed 7,994 batch-loss 5.0619 epoch-elapsed 0h00m05s total-elapsed 0h34m25s\n",
            "epoch 9 batch 3/89 processed 8,004 batch-loss 3.3285 epoch-elapsed 0h00m06s total-elapsed 0h34m27s\n",
            "epoch 9 batch 4/89 processed 8,014 batch-loss 10.6501 epoch-elapsed 0h00m09s total-elapsed 0h34m30s\n",
            "epoch 9 batch 5/89 processed 8,024 batch-loss 8.7857 epoch-elapsed 0h00m14s total-elapsed 0h34m34s\n",
            "epoch 9 batch 6/89 processed 8,034 batch-loss 9.6836 epoch-elapsed 0h00m16s total-elapsed 0h34m36s\n",
            "epoch 9 batch 7/89 processed 8,044 batch-loss 11.1093 epoch-elapsed 0h00m20s total-elapsed 0h34m40s\n",
            "epoch 9 batch 8/89 processed 8,054 batch-loss 7.3027 epoch-elapsed 0h00m22s total-elapsed 0h34m43s\n",
            "epoch 9 batch 9/89 processed 8,064 batch-loss 10.2494 epoch-elapsed 0h00m25s total-elapsed 0h34m46s\n",
            "epoch 9 batch 10/89 processed 8,074 batch-loss 5.1587 epoch-elapsed 0h00m27s total-elapsed 0h34m48s\n",
            "epoch 9 batch 11/89 processed 8,084 batch-loss 5.3416 epoch-elapsed 0h00m29s total-elapsed 0h34m50s\n",
            "epoch 9 batch 12/89 processed 8,094 batch-loss 8.0769 epoch-elapsed 0h00m32s total-elapsed 0h34m53s\n",
            "epoch 9 batch 13/89 processed 8,104 batch-loss 6.2124 epoch-elapsed 0h00m34s total-elapsed 0h34m55s\n",
            "epoch 9 batch 14/89 processed 8,114 batch-loss 7.5338 epoch-elapsed 0h00m37s total-elapsed 0h34m57s\n",
            "epoch 9 batch 15/89 processed 8,124 batch-loss 6.8235 epoch-elapsed 0h00m39s total-elapsed 0h34m59s\n",
            "epoch 9 batch 16/89 processed 8,134 batch-loss 9.6223 epoch-elapsed 0h00m41s total-elapsed 0h35m02s\n",
            "epoch 9 batch 17/89 processed 8,144 batch-loss 5.3549 epoch-elapsed 0h00m43s total-elapsed 0h35m04s\n",
            "epoch 9 batch 18/89 processed 8,154 batch-loss 8.5649 epoch-elapsed 0h00m45s total-elapsed 0h35m06s\n",
            "epoch 9 batch 19/89 processed 8,164 batch-loss 12.3533 epoch-elapsed 0h00m49s total-elapsed 0h35m10s\n",
            "epoch 9 batch 20/89 processed 8,174 batch-loss 3.4827 epoch-elapsed 0h00m51s total-elapsed 0h35m12s\n",
            "epoch 9 batch 21/89 processed 8,184 batch-loss 6.1145 epoch-elapsed 0h00m53s total-elapsed 0h35m14s\n",
            "epoch 9 batch 22/89 processed 8,194 batch-loss 6.7158 epoch-elapsed 0h00m57s total-elapsed 0h35m17s\n",
            "epoch 9 batch 23/89 processed 8,204 batch-loss 10.9263 epoch-elapsed 0h00m59s total-elapsed 0h35m20s\n",
            "epoch 9 batch 24/89 processed 8,214 batch-loss 8.5156 epoch-elapsed 0h01m03s total-elapsed 0h35m23s\n",
            "epoch 9 batch 25/89 processed 8,224 batch-loss 9.7179 epoch-elapsed 0h01m06s total-elapsed 0h35m26s\n",
            "epoch 9 batch 26/89 processed 8,234 batch-loss 5.8273 epoch-elapsed 0h01m08s total-elapsed 0h35m29s\n",
            "epoch 9 batch 27/89 processed 8,244 batch-loss 3.9226 epoch-elapsed 0h01m10s total-elapsed 0h35m31s\n",
            "epoch 9 batch 28/89 processed 8,254 batch-loss 6.7617 epoch-elapsed 0h01m13s total-elapsed 0h35m33s\n",
            "epoch 9 batch 29/89 processed 8,264 batch-loss 7.1396 epoch-elapsed 0h01m15s total-elapsed 0h35m36s\n",
            "epoch 9 batch 30/89 processed 8,274 batch-loss 7.6200 epoch-elapsed 0h01m17s total-elapsed 0h35m38s\n",
            "epoch 9 batch 31/89 processed 8,284 batch-loss 4.7747 epoch-elapsed 0h01m19s total-elapsed 0h35m39s\n",
            "epoch 9 batch 32/89 processed 8,294 batch-loss 11.1597 epoch-elapsed 0h01m22s total-elapsed 0h35m43s\n",
            "epoch 9 batch 33/89 processed 8,304 batch-loss 9.0473 epoch-elapsed 0h01m25s total-elapsed 0h35m46s\n",
            "epoch 9 batch 34/89 processed 8,314 batch-loss 4.6962 epoch-elapsed 0h01m27s total-elapsed 0h35m48s\n",
            "epoch 9 batch 35/89 processed 8,324 batch-loss 6.1899 epoch-elapsed 0h01m30s total-elapsed 0h35m50s\n",
            "epoch 9 batch 36/89 processed 8,334 batch-loss 7.2990 epoch-elapsed 0h01m33s total-elapsed 0h35m53s\n",
            "epoch 9 batch 37/89 processed 8,344 batch-loss 7.3096 epoch-elapsed 0h01m34s total-elapsed 0h35m55s\n",
            "epoch 9 batch 38/89 processed 8,354 batch-loss 7.9038 epoch-elapsed 0h01m37s total-elapsed 0h35m58s\n",
            "epoch 9 batch 39/89 processed 8,364 batch-loss 7.9641 epoch-elapsed 0h01m40s total-elapsed 0h36m01s\n",
            "epoch 9 batch 40/89 processed 8,374 batch-loss 4.2086 epoch-elapsed 0h01m42s total-elapsed 0h36m03s\n",
            "epoch 9 batch 41/89 processed 8,384 batch-loss 6.7082 epoch-elapsed 0h01m45s total-elapsed 0h36m05s\n",
            "epoch 9 batch 42/89 processed 8,394 batch-loss 2.8968 epoch-elapsed 0h01m46s total-elapsed 0h36m07s\n",
            "epoch 9 batch 43/89 processed 8,404 batch-loss 8.3722 epoch-elapsed 0h01m48s total-elapsed 0h36m09s\n",
            "epoch 9 batch 44/89 processed 8,414 batch-loss 8.5971 epoch-elapsed 0h01m50s total-elapsed 0h36m11s\n",
            "epoch 9 batch 45/89 processed 8,424 batch-loss 8.4062 epoch-elapsed 0h01m53s total-elapsed 0h36m14s\n",
            "epoch 9 batch 46/89 processed 8,434 batch-loss 5.0263 epoch-elapsed 0h01m56s total-elapsed 0h36m17s\n",
            "epoch 9 batch 47/89 processed 8,444 batch-loss 7.0841 epoch-elapsed 0h01m58s total-elapsed 0h36m19s\n",
            "epoch 9 batch 48/89 processed 8,454 batch-loss 6.2813 epoch-elapsed 0h02m01s total-elapsed 0h36m21s\n",
            "epoch 9 batch 49/89 processed 8,464 batch-loss 5.4369 epoch-elapsed 0h02m03s total-elapsed 0h36m24s\n",
            "epoch 9 batch 50/89 processed 8,474 batch-loss 6.3524 epoch-elapsed 0h02m05s total-elapsed 0h36m26s\n",
            "epoch 9 batch 51/89 processed 8,484 batch-loss 11.1029 epoch-elapsed 0h02m08s total-elapsed 0h36m29s\n",
            "epoch 9 batch 52/89 processed 8,494 batch-loss 5.6651 epoch-elapsed 0h02m11s total-elapsed 0h36m31s\n",
            "epoch 9 batch 53/89 processed 8,504 batch-loss 7.4381 epoch-elapsed 0h02m13s total-elapsed 0h36m34s\n",
            "epoch 9 batch 54/89 processed 8,514 batch-loss 3.5785 epoch-elapsed 0h02m15s total-elapsed 0h36m36s\n",
            "epoch 9 batch 55/89 processed 8,524 batch-loss 8.5778 epoch-elapsed 0h02m19s total-elapsed 0h36m40s\n",
            "epoch 9 batch 56/89 processed 8,534 batch-loss 5.8345 epoch-elapsed 0h02m21s total-elapsed 0h36m42s\n",
            "epoch 9 batch 57/89 processed 8,544 batch-loss 8.9391 epoch-elapsed 0h02m24s total-elapsed 0h36m45s\n",
            "epoch 9 batch 58/89 processed 8,554 batch-loss 4.8166 epoch-elapsed 0h02m26s total-elapsed 0h36m47s\n",
            "epoch 9 batch 59/89 processed 8,564 batch-loss 5.1543 epoch-elapsed 0h02m28s total-elapsed 0h36m49s\n",
            "epoch 9 batch 60/89 processed 8,574 batch-loss 5.3573 epoch-elapsed 0h02m30s total-elapsed 0h36m51s\n",
            "epoch 9 batch 61/89 processed 8,584 batch-loss 8.1581 epoch-elapsed 0h02m33s total-elapsed 0h36m54s\n",
            "epoch 9 batch 62/89 processed 8,594 batch-loss 6.7504 epoch-elapsed 0h02m36s total-elapsed 0h36m57s\n",
            "epoch 9 batch 63/89 processed 8,604 batch-loss 7.0467 epoch-elapsed 0h02m38s total-elapsed 0h36m59s\n",
            "epoch 9 batch 64/89 processed 8,614 batch-loss 8.8647 epoch-elapsed 0h02m41s total-elapsed 0h37m01s\n",
            "epoch 9 batch 65/89 processed 8,624 batch-loss 9.9900 epoch-elapsed 0h02m44s total-elapsed 0h37m04s\n",
            "epoch 9 batch 66/89 processed 8,634 batch-loss 4.6612 epoch-elapsed 0h02m46s total-elapsed 0h37m06s\n",
            "epoch 9 batch 67/89 processed 8,644 batch-loss 7.2914 epoch-elapsed 0h02m48s total-elapsed 0h37m09s\n",
            "epoch 9 batch 68/89 processed 8,654 batch-loss 5.3427 epoch-elapsed 0h02m50s total-elapsed 0h37m11s\n",
            "epoch 9 batch 69/89 processed 8,664 batch-loss 6.0674 epoch-elapsed 0h02m53s total-elapsed 0h37m14s\n",
            "epoch 9 batch 70/89 processed 8,674 batch-loss 2.4415 epoch-elapsed 0h02m55s total-elapsed 0h37m15s\n",
            "epoch 9 batch 71/89 processed 8,684 batch-loss 12.9638 epoch-elapsed 0h02m58s total-elapsed 0h37m19s\n",
            "epoch 9 batch 72/89 processed 8,694 batch-loss 5.6151 epoch-elapsed 0h03m01s total-elapsed 0h37m21s\n",
            "epoch 9 batch 73/89 processed 8,704 batch-loss 6.0029 epoch-elapsed 0h03m03s total-elapsed 0h37m24s\n",
            "epoch 9 batch 74/89 processed 8,714 batch-loss 7.2661 epoch-elapsed 0h03m06s total-elapsed 0h37m27s\n",
            "epoch 9 batch 75/89 processed 8,724 batch-loss 7.1991 epoch-elapsed 0h03m09s total-elapsed 0h37m29s\n",
            "epoch 9 batch 76/89 processed 8,734 batch-loss 6.7569 epoch-elapsed 0h03m11s total-elapsed 0h37m32s\n",
            "epoch 9 batch 77/89 processed 8,744 batch-loss 17.2611 epoch-elapsed 0h03m15s total-elapsed 0h37m36s\n",
            "epoch 9 batch 78/89 processed 8,754 batch-loss 7.3127 epoch-elapsed 0h03m19s total-elapsed 0h37m39s\n",
            "epoch 9 batch 79/89 processed 8,764 batch-loss 11.3423 epoch-elapsed 0h03m23s total-elapsed 0h37m43s\n",
            "epoch 9 batch 80/89 processed 8,774 batch-loss 8.8718 epoch-elapsed 0h03m26s total-elapsed 0h37m47s\n",
            "epoch 9 batch 81/89 processed 8,784 batch-loss 6.3973 epoch-elapsed 0h03m29s total-elapsed 0h37m50s\n",
            "epoch 9 batch 82/89 processed 8,794 batch-loss 6.1195 epoch-elapsed 0h03m31s total-elapsed 0h37m52s\n",
            "epoch 9 batch 83/89 processed 8,804 batch-loss 3.5790 epoch-elapsed 0h03m33s total-elapsed 0h37m54s\n",
            "epoch 9 batch 84/89 processed 8,814 batch-loss 7.5597 epoch-elapsed 0h03m35s total-elapsed 0h37m56s\n",
            "epoch 9 batch 85/89 processed 8,824 batch-loss 6.7614 epoch-elapsed 0h03m38s total-elapsed 0h37m59s\n",
            "epoch 9 batch 86/89 processed 8,834 batch-loss 4.8704 epoch-elapsed 0h03m40s total-elapsed 0h38m00s\n",
            "epoch 9 batch 87/89 processed 8,844 batch-loss 2.4304 epoch-elapsed 0h03m41s total-elapsed 0h38m02s\n",
            "epoch 9 batch 88/89 processed 8,854 batch-loss 5.8242 epoch-elapsed 0h03m43s total-elapsed 0h38m04s\n",
            "epoch 9 batch 89/89 processed 8,860 batch-loss 5.9475 epoch-elapsed 0h03m45s total-elapsed 0h38m05s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from src.util import format_elapsed\n",
        "\n",
        "np.random.seed(1)\n",
        "trainer = dy.AdamTrainer(model)\n",
        "total_processed = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(10):\n",
        "    np.random.shuffle(train_parse)\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    for start_idx in range(0, len(train_parse), batch_size):\n",
        "        dy.renew_cg()\n",
        "        batch_losses = []\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        for i in range(batch_size):\n",
        "            if start_idx + i < len(train_parse):  # Deal with final batch edge case\n",
        "                gold_tree = train_parse[start_idx + i]\n",
        "                sentence = [(leaf.tag, leaf.word) for leaf in gold_tree.leaves()]\n",
        "                loss = hinge_loss(sentence, gold_tree)\n",
        "                batch_losses.append(loss)\n",
        "                total_processed += 1\n",
        "\n",
        "        # YOUR CODE END\n",
        "        batch_loss = dy.average(batch_losses)\n",
        "        batch_loss_value = batch_loss.scalar_value()\n",
        "        batch_loss.backward()\n",
        "        trainer.update()\n",
        "\n",
        "        print(\n",
        "            \"epoch {:,} \"\n",
        "            \"batch {:,}/{:,} \"\n",
        "            \"processed {:,} \"\n",
        "            \"batch-loss {:.4f} \"\n",
        "            \"epoch-elapsed {} \"\n",
        "            \"total-elapsed {}\".format(\n",
        "                epoch,\n",
        "                start_idx // batch_size + 1,\n",
        "                int(np.ceil(len(train_parse) / batch_size)),\n",
        "                total_processed,\n",
        "                batch_loss_value,\n",
        "                format_elapsed(epoch_start_time),\n",
        "                format_elapsed(start_time),\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "907f3df6",
      "metadata": {
        "id": "907f3df6"
      },
      "source": [
        "### Evaluating the model\n",
        "Evaluate the model and report the Recall, Precision, and F-Score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4eac5620",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eac5620",
        "outputId": "4449250a-7fee-4f2e-d876-f208b7d9e9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev-fscore (Recall=74.77, Precision=76.28, FScore=75.52) \n"
          ]
        }
      ],
      "source": [
        "from src import evaluate\n",
        "\n",
        "evalb_dir = \"EVALB/\"\n",
        "!chmod +x EVALB/evalb\n",
        "\n",
        "test_predicted = []\n",
        "for tree in test_treebank:\n",
        "    dy.renew_cg()\n",
        "    sentence = [(leaf.tag, leaf.word) for leaf in tree.leaves()]\n",
        "    predicted, _ = parse(sentence, None, False)\n",
        "    test_predicted.append(predicted.convert())\n",
        "\n",
        "test_fscore = evaluate.evalb(evalb_dir, test_treebank, test_predicted)\n",
        "\n",
        "print(f\"dev-fscore {test_fscore} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "nGLHewlIyCmk",
      "metadata": {
        "id": "nGLHewlIyCmk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
